{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b5767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. Module Import '''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, copy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import rexnetv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871d0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.11.0+cu113  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "''' 2. 딥러닝 모델을 설계할 때 활요하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "85259721",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIM = 'SGD' # Adam\n",
    "MODEL = 'RexNet' # ResNet34 ResNet18 RexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9f8a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3. 이미지 데이터 불러오기(Train set, Test set 분리하기)'''\n",
    "# preprocessing 정의\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, img_path, txt_path, transforms = None):\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.img_list = [os.path.join(img_path, i.split()[0]) for i in lines]\n",
    "            self.label_list = [i.split()[1] for i in lines]\n",
    "            self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            img_path = self.img_list[index]\n",
    "            img = Image.open(img_path)\n",
    "            img = self.transforms(img)\n",
    "            label = self.label_list[index]\n",
    "        except:\n",
    "            return None\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "img_path = '/root/share/datasets/ICNGC_data'\n",
    "trainset_txt = {'fold1': './splits/Custom_Paper/fold2345_all.txt',\n",
    "                'fold2': './splits/Custom_Paper/fold1345_all.txt',\n",
    "                'fold3': './splits/Custom_Paper/fold1245_all.txt',\n",
    "                'fold4': './splits/Custom_Paper/fold1235_all.txt',\n",
    "                'fold5': './splits/Custom_Paper/fold1234_all.txt'\n",
    "               }\n",
    "testset_txt = {'fold1': './splits/Custom_Paper/fold1_all.txt',\n",
    "               'fold2': './splits/Custom_Paper/fold2_all.txt',\n",
    "               'fold3': './splits/Custom_Paper/fold3_all.txt',\n",
    "               'fold4': './splits/Custom_Paper/fold4_all.txt',\n",
    "               'fold5': './splits/Custom_Paper/fold5_all.txt',\n",
    "              }\n",
    "\n",
    "train_loader = {}\n",
    "test_loader = {}\n",
    "\n",
    "for i in range(len(trainset_txt)):\n",
    "    train_dataset = Data(img_path, trainset_txt['fold'+str(i+1)], data_transforms['train'])\n",
    "    test_dataset = Data(img_path, testset_txt['fold'+str(i+1)], data_transforms['val'])\n",
    "    train_loader['fold'+str(i+1)] = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    test_loader['fold'+str(i+1)] = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "320a77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([2, 3, 224, 224]) type: torch.FloatTensor\n",
      "y_train: 2 type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (1) '''\n",
    "for (X_train, y_train) in train_loader['fold1']:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', len(y_train), 'type:', type(y_train))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ee0681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAABwCAYAAABo+iCPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAksklEQVR4nO19baxlZbHmU/Wutfc+/UXPBURBhduEq92QtBmBH3RiS0aJCST9Q9Bfo2j8QDEaA63RMYL4S418g1GSyfxBnUtuYkI0Y3Q0NxEIoF4G5DZIADNKJwxwpRGh++z1Vs2PqnrXWuc0zd6nmz6cZhUe+5x91tfe51m1qp56ql5SVcVgg61B49W+gMEGW6kN4B1szdoA3sHWrA3gHWzN2gDewdasDeAdbM3aAN7B1qwN4B1szdoA3sHWrB018J522mm49NJLj9bpjnkbPs8jAN7HH38cn/70p7FlyxZMJhNs2rQJO3bswA033ICXX375SFzjqthTTz2FD33oQ9i8eTM2bdqEXbt24YknnnjNz3ssfp6PPvoovvjFL+K8887DZDIBEeFPf/rTYR+3Opydf/rTn+KSSy7BeDzGRz7yEZx11llYXFzEb37zG+zevRsPP/wwfvCDHxz2RR5te/HFF3H++edj3759+OpXv4q6rnHddddh586deOCBB3D88ce/Juc9Vj/Pe+65BzfeeCO2bduGrVu34oEHHjgyB9YV2hNPPKEbNmzQd77znbp3795lv3/sscf0+uuvLz+feuqp+tGPfnSlpzuq9q1vfUsB6H333Vde27Nnj6aU9Ctf+cprcs5j+fN87rnn9IUXXlBV1e985zsKQJ988snDPu6KwXvZZZcpAL3rrrtm2n7ph/3cc8/pFVdcoWeddZauX79eN27cqB/4wAf0gQceWLbvjTfeqNu2bdOFhQXdvHmzvvvd79bbb7+9/P6FF17QL3zhC3rqqafqaDTSE088Ud/3vvfp7373u7LN3//+d92zZ48+88wzr3qt55xzjp5zzjnLXr/gggv09NNPn+n9zmvH8ufZtSMJ3hXHvHfeeSe2bNmC8847b0X7P/HEE/jJT36Ciy66CNdeey12796Nhx56CDt37sTevXvLdrfddhs+//nPY9u2bbj++uvxjW98A+9617tw7733lm0uu+wyfO9738MHP/hB3HrrrbjyyiuxsLCAPXv2lG3uu+8+bN26FTfffPMhr0tE8OCDD+Lss89e9rtzzz0Xjz/+OP72t7+t6D0fyo7Vz/M1tZUgft++fQpAd+3aNfM+Sz3F/v37Nefc2+bJJ5/U8Xis11xzTXlt165deuaZZx7y2Mcdd5xefvnlh9zm17/+tQLQq6666pDbPfPMMwqgdw1ht9xyiwLQRx555JDHmNeO5c9zqR1Jz7uihO2FF14AAGzcuHHFN814PC7f55zx/PPPY8OGDXjHO96B3//+9+V3mzdvxl/+8hfcf//9OOeccw56rM2bN+Pee+/F3r17cfLJJx90m/e+973QGXT3kdF3ry9sMpn0tjlSdix/nq+lrShs2LRpEwAc1uNTRHDdddfhjDPOwHg8xgknnIATTzwRDz74IPbt21e2+/KXv4wNGzbg3HPPxRlnnIHLL78cd911V+9Y3/72t/GHP/wBb3vb23Duuefi6quvXjGttbCwAAA4cODAst/t37+/t82RsmP583xNbaUu++STT54reVn6mPvmN7+pAPTjH/+4/uhHP9Kf//zn+otf/ELPPPNM3blzZ2/fF198UX/84x/rpZdeqieddJIC0K9//eu9bfbu3au33HKL7tq1S9etW6eTyUR/9rOfzf2+cs46Ho/1M5/5zLLffe1rX1MAJXM+knasfp5L7XXBNnzqU59SAHr33XfPtP3SD3v79u16/vnnL9vulFNOWfZhd+3AgQN64YUXakpJX3755YNu8/TTT+spp5yiO3bsmOnaltrZZ599ULbh/e9/v27ZsmVFx3w1O5Y/z669LtiGL33pS1i/fj0+8YlP4Omnn172+8cffxw33HDDK+6fUloWM91xxx146qmneq8999xzvZ9HoxG2bdsGVcV0OkXOufdYBIA3velNOPnkk3uP/pdeegmPPPIInn322Vd9bxdffDHuv/9+/Pa3vy2vPfroo/jVr36FSy655FX3X4kdy5/na2UrrrCdfvrp+OEPf4gPf/jD2Lp1a68idPfdd+OOO+44ZO39oosuwjXXXIOPfexjOO+88/DQQw/h9ttvx5YtW3rbXXDBBXjzm9+MHTt24KSTTsKePXtw880348ILL8TGjRvx/PPP461vfSsuvvhibN++HRs2bMAvf/lL3H///fjud79bjnPffffh/PPPx1VXXYWrr776kO/ts5/9LG677TZceOGFuPLKK1HXNa699lqcdNJJuOKKK1b6kR3SjuXPc9++fbjpppsAoMTXN998MzZv3ozNmzfjc5/73Mo+tMN13X/84x/1k5/8pJ522mk6Go1048aNumPHDr3pppt0//79ZbuDUTtXXHGFvuUtb9GFhQXdsWOH3nPPPbpz587eY+773/++vuc979Hjjz9ex+Oxnn766bp7927dt2+fqtpjb/fu3bp9+3bduHGjrl+/Xrdv36633npr7zrnpXb+/Oc/68UXX6ybNm3SDRs26EUXXaSPPfbYij+nWe1Y/DyffPJJBXDQr1NPPXXFnxWpDnMbBlubNuh5B1uzNoB3sDVrA3gHW7M2gHewNWsDeAdbszaAd7A1awN4B1uzNnOFrdpCAAH5bwAOAJgAGANcAaMxsDAZYzJeh6oeIVU1qtEIdT1CVY2RqhogQiZFIwIAICIQAZobYDqFNA0gigyBQtFAkFXRSAPIIqACUYGoQgggMJgZygkigiZniAiIAIBsWxJAFZoFEOPFRfxnVagK1PQdAAAWIDEhsSIBqBhgAlQAaQAoQLDXUrIvZsaf780r+vDJLnawg9gs5YfZwbsAEAOqgEwAGgOpAhIDqa5QTyaYjCdIqUbiCuAKCkZWBSkAJWRVCAhEBFX7w0MVWTJEE4AMoSi/KBQCkEBIoSzQAD7aRwZJBkQAZAACgKAEKKltL2oXDYAEYPWt1D6gzAqoHUIZYChYgeS4UrFt2a8L9lYgAJgIysPDa7VsZvCu3zBGSgkHRg2yKDglEBQEQpVGGI8WUI1GSFyByDwi1P74OQtUBY1mCCmIGMwEZIWKAjCvLiAoAIEiB3ghAGWoiqEW8Y970mweFKIgsRsM5IDrbFkArAZgUmAqdoa4yZmB5MdX39YduR1X/PxkXwKF6Mq87mB9G03WYed/eR9+e+89+Ouzz8y0z8zg3bz5eDAzmpzR5GxeK2eoABXXGE8mqOqRAVcVKg4aAURte2EDIBFASmD3r0qOHlX0/lP3weXX9hoRmRuFmMdUGHjhgItzu8ePAygAVjue+L9d4DLDnwrtOcEO5gzEUz7Ai443HuzwrKoqpMkE83yiM4P3H/7hRAgpDjQNFhcXMV1cRGocvKlCNRqDUwLAkMYiVwAeW7YXRCDzfEABqKp5WSUBROx7KEQsJhV/LUxVQR6OkMcZtMQrqocmAX51F6vSntPxB2JCYgIzg0lBms2Lx/lg94A/IErgK+59Bzt8e+nFF/C//uWf59pnZvBu2HQcFpsG+cDLyGqP+EQZUCClClwl+yMLIEoQUU/KPCwAijtkDeiiAFQ1QzVD1IALCpD5z2HhUtVAy+49A2iGMQKpwkPkAnsFQdyzxtZMhMTJgUsgFRAETB7nxvnC67LH7ACE1PLAwVZs64/7T/jHf3on/u+TT+CFZ5frmA9lM4NXuXLcMEgZVRpZvKcK4oQMNsBKeNrwa62RKljIwwRzl0pqHtcyqOKFxY+h2nk2++FYbHeNkGAZeIEEcqbA4nJ4kqWdDJ8IIGakZOAleFJHDAJBwUD2RFHVgeteHX77DYTBim2ycSM+99+uwtv/8Z340if/69z7zwzeaaMQJUArMBt3pMnAYckZQTSDShDKIOYCPAovpu5HA8CRlBXzMKF4PTYagLIxFL5bsADupIsZeLsvmBeOfwnGckTYACJ/QpgXNtgKmIzT0JLRUUvv+bPAwokBvSu1Ay++iDv/+XZoBv6+b/6OjJnBKwJkJfPAbJEekRhn5chkZQjYvKk5RKQlx1FVgCxDp85rqlJCCOM/u+62vQkkezxaMjKzVHisSOiA7L8PPjWlZF4zZ/O2qmBKIOISLDMTmKpyQygTJHgzy+jK00LAQ8x7GKaq+Pff3r/i/ecAL0HF/1QU3FGbgQMAmMEgS7c84Ix4tMSO4bdKtq9tUqbhgc3DiXh84K/ZDuT0WgvMbsgAGP8KIifbWnCptqGJXS4jsT8hmDwPszid/Xyq2itDKpEnb1QuabDVsTnAKw4mgIidUsq9Px4lABCQSilAEFqwAAZdkkjl1Y+b/Ssog7bCYk/8yvbUphwD2tJa1Ak8IwQALO4lUUy7QO/8nsgZBhBI7TVmAiUGE4PVAN40TbkeYU/UCFZQGcC7ajYXeFWcvw22QFuQlVKnJz6QbPUFspDAvG9sy23sqwrJ0rs5IhIGUIDpUTQEZDGwe27y+DWOVwBNBBFBLuxFp2AB97opGVPCVtkgAjgRUuXxsBipkahqbyw/lkO5c8TBjrbN1z2sBBaCOA+7vP5MXuFyl0T2xWRgEP/DMxjhSVVgDEWHf9WoZBR+yjlZYaioMRHqsBbjcwX9GyT0ERE2qC6l5hTMCSmN2oSNGSkpUuVFEr9ZIQTSqI3beycQoNOVfeqDHRGbnSrrcKOE9o8d1vV4Vh5my/qDbUCfzloK/F7yRt09vNoVTEWUxdR423J9sGRK4AUJqJeizQNLgBcu7GECpYSULKVkZlScwAngyhJKEQEJWSXRq3+SjfKzk0QhZLDVsLk8L5F5zK6n6iqjClMg6uFDgKxPh3bLr3GsUgvwZFC7UI/wJBiAsm17EwhZkUEiCQxPjE5CCGMPiNlUb6MRKq7KdVScQKyeiyqY2ZVqHoKIGNNiFQp0LmmwGa2qK6zfuAH7/uP5wz/WzFuKSVbIyVXyEKHDeCIxO2OgSFGhSjDllSpUo7olsJdM2qPMQCaoslG6XJl3g8fLSiBJ7oGzJ1fOGECc5bKbxfYSqGZQImQVk1WCUFUjpLpGqhJGowmqVIHtTRjHy4RUoZTWVAkgdcFQNk6XrAIHRM45wHceU1UceHn/ETnWzOAlShCvhRLYvB4b4wBkV4qxFw0ESQ3oKvHoJ4hY2djiTQNv1ohvK3iGB1DowZz3LRU1BjQZdUV2jJq4aA40eDkiiDLAVm7mBKRUY2GyDqPRCFVVg1N9EJbCbiqwX7e61oEUyu3lxaNkeQ1xsFez3GTkJmM8Hh90Euc8Ngd4Gcz2+GXYIxpMRS8QFSookCIuzQBxqw5jNu+6NNQArCQLDhqL0Lgmoo2FBYrGPL/HsokZieO42mEEPAZPipoZSRnj0QLWLWxAXddgTjhI+cRvRLHnClFhMoioV8WL6xVmEwYNNpfVdY1tZ23Fv/3ugcM6zszgjXiSHVzM5BUn+yMCJuSGKJjY6bROiYFMp0Dl+1B2OefKXpolcvjEjnaUEOsQYFpiCiWYerlXIr+z41cKVAZAIGEyXod169Z5gmbqh8JuFOCLe33px7OqnvB1aMFQpQ3l4bltOp0eNnCBOcCblJzgirjUyHx76icDlppo3B7BFZTJ+2e67II9+uN7gsIDgVLOhahpfdt2CRALCIREVlSwUIA8yiBn5aLQwODEEGpAzCCqMBrVqKoKVTVCsAQiUpgEoGX4tAPs4J81eOgOVrsFj7VuRXuyhmwuzxulYWVYUsNcVFZ9gQ15FQ7WR2ZNMwjqwVmv8mExEYRdnN4p33bIMgMkW6hQMVkxIQVYLR6OR3wBLxKIGcwV6rouRQmiftUszhU/qrRa4pz7Ms2iu6AlxZk1bMQErhh5ceVdIZQYXNXQ6bQXvh3KRuMRFg8srvicc8S8rZdRtmStuCEOOit4COtHQ3hgbZyFWBrrdsu2/XACBCQi1MyQOiFxQlWl0iBJxEiJQSTuNZIngtxeaxq5QN4E80F5AQ7K8Kal160VwXe/VBXEYrefhkrNZZJrALwbj9uAA/sPYPHAwYsqKnpYwAWAbWf/Z0zWbcLWM96B//k//jumi6+ejAXHvlKbPWzwuNYoTgcdu0gFbcHAWoCMDqNOTOnFqSXFifZ7Th5RipbiGpGFADWzATclpMRggqltmTz5aitoodFlZgsn2GSN0Z4UYYJ4X10wfSpWHNFOBa6v52jfX2Ea1kDYsG79Orz99Lfj2Weew/976pm2idWT3CNFVD/5x0chixmnnHgC6lF9SPCGk9p/mJTZXGFDOTkDwlHfb9nVCBfgHRadvaGaoZINwGgVZNR9/JJxUSkxwEZbWZzqHKyLxpnJVQ5aqnyq3jxEltBVKVmIIwrAmkFFLRGTrIC3v7fhgpZChPSUbgf/6x6sSPN6NHYOfWG8HlX6D0xFkOqE8WSMd2z9J5xw/An41//9r1hcPLxS90t/tcVg7rzjjlf8zAD73MbjMfbv33/I7Wax2cHLbUXJG3SR1foNQO61oFDJgOYyJwEw3YHFjdHSIy6NZYgSsgvYmQhUWVIYYUFdV6hrLl6YjOAAyrn9AtV72oJvpqDP1DTAKGSEJXbUoddErNwrhVAu79uu2W62LFb8sJb89o/xejUiW3br4f/zcO/1PM14afoS/vBvD2P9hvVomsPsgB6Zc8A0vyogVbWsqnS4NkfMG2dHG+rCerhcUWBgUAFrLkWD0OkqOZfgCVzEuSXx8YKAJV3m0VJiVFWFuk4lJi7twbYX2j63DAWVJ0R77rhup+SKLgKFQdBssx9UshUoSmzcBW/cjOKx8evfVK0o8Eo2nU7x/F+fP/wT1QTsP/ojAObUNsQ3QK+9dqk5nbD0LjTFge1fOoRci9AKfbybgal43qrizjHivK0QyOJp7cWlVpljBA9i25v/tXvGOpCRMyRn97ZWzTPwtmJ44rYc3b49LbHbG9G49lCsycDfm1W5htlVZf4vURQM/NX4F20rOXp/684fNxKcmPrhxkzx66KzZSZUFRXgFpB09uuCp5dQwbDIMdBEFdaB0V4POVenzuGWGRGIkkjLenTv0ZLIoRUovRFNpqs/bGV28FKLm1JpCgEL3EtpBqHtIYsuiigksACaXNCjNqIpABteMaUWvETqHrV7ITiIxycQJeeOFRneEg+UJ4CBlLzljkrIUJIy98QWu/fb7eO77hyJAG9XFvqGt/4D6jW32cMGis6HeKH1aiRtu08qXK9LttnDVBAo2TwE41vDTwdDESGDJWp2Botnuev+ut92PG8AF0Bpmy/xrfiAPenHxAd75NtTxRM4aH9b9XaobN3NlDpc92BHFbjAXDFvBkBQYuuopYyQOJJa+Zg0QUFQEig1nkSZsXtYAF5MIISSjEiRPRxRsqSPPP4gAjJn7+p1jbAszfIJ0AoQOwYH9aXi4ULLaaoAOQom2h5D1JgSgUA4eOrOU0YElNWVceTJYYI37g22CjZ3JwV5tm9e0X5nU2usiTG4X/sfleJFRx/mx4mfGSBBckFOiTkdgORHsQO2pHrbIu9xaO4WRLpdvwTN7I94ApQthMhS5Jlt+ADveRMj8aHIWQzQ3g9nSZxzvFiuNntDGwGThQXUkxH279+P6UuHJ3l8NZsTvBF/tkWJAFMJAgqgjEsN6HaZAaL2kRx7R2jReLLUjW1jRkOSTnZfig5eXMhtUaELbDtqlIwZAgdo0/ho1dypqHXLLX6DqLacdfDcFGOihng3bN1xG3DKqW/HZGGMA4uL+NMfH3/Nzzm3583iWSaheLaosYV3U485xauvbVauaGeXGbi6Vayu3qGc1zYCKIaZBHjtsS9ZkKcZuXEge/LFnIrf7lJrTZMxXVyELjYWVnT5BQViHkW8h0gkgeQi+4inCZTjnQ/20r4X8diD/35UzzkzeHPOLQhDe6AosWnfWhqJ0OVC++DsagiiwbGbFcaADxIBqw2CDp0EKwNKaKYZkq2K1qXN7AHBPTDmLGXCJRppnxQ+iLf71BDnjk2DnEryl9QAyxIdHEPCtlo2Z8Lm8w3C81h6VhiAkGtrQba3jqOF7LLChYtluj8XT4zI/gGITWG3cEGj3wHaZGheXpYs4UPp8rV4tWkaNE1jQCRCVZo9O6GGUz69m0G7LaHOsuCNy/O+HmwO8Nojn7nra7rJl5bwIUBncxZDQtOnswD0ve5BwFd+R36zsPa2JcBUaCG68BdLwUGcbQiKK8Tnvh2F8gzcn3DeSeJ6VbslbUYDUba6Nrsk0ltvQknVE3JHgkTWkNnO5vWqmQKkbFk7gKAplrIDYUtfJwC5aaAudVTnlo36skk+5EAj1xnHEJMsLatQrpcIFRikgGQxLrojqLf3EGtcpIPedG/k6trrxeYGb5mzoG3DYzv7CzAaiXywc7fk4t5xCTDVdQVR5bJN+oAuVTZFOScLfIC0FIBblYzKuUQDuH4F7qEtxC1BCSJytaqfzU6jThghnfDhjapleD3aHOAdF1kkUXeiY+ENAERXQ/szEGBsQ4FuqBDDQEijyXE5eElt/q96ApgAlCnqSzxqnM9Yhxgr1b6Pdk0Km5Ma8koDtfPDnfhWISBRZBcNRSgxeN35zZzakbv5ZwZvXdedNprOmCON0nD30br8AkMuGe03Xc8dvy+etzMetf+vdsoe2s6RWIKjHm8r0dnhl+X8XUgpGRb7KhSavUBB6N0UzB4SEQCkXqVwsBltuWLrsG2usCEsPGmACC7WLtpaXeJZO98v7dgNK0DugBhqKV/XCzMAIXIAckkWu14eQNtECYDV4mIo9Y6F8kRoijYj2I1SpfMZvglWq6CUyjyH+P1gM1g87Y6gzdWAGcR9ZNntI34JeKVdx6EL2p6Kq/u+SgKH8ghHz5t35jwc5HGtZfslXxIz0FyUHsdT9R4u21lFoTGulBTWLaFFEF8A6sxHqmL2w+E3EQ62cpurwqbBMcX/d8KEAi5j922A9NLYdmlL9NIniGtuy0wzDxOibyHizS7j0Vbl+pSbzRCJHjXzukBb7WOK4dCdY5C1+Chlk2YyI3ECufiGiVClhKquy2sDeFfPZh8uHbIZUm8VtwnoiNUntQW4J+3+qDYe1usL7u3amNHiWAvkpeN14/dL/w3hDIdmOOiyzpR2w73H5xoiITNynpriaR8raAaPTQROFVJVoUqj0n3MnMCpAuqRve4x8ADe1bPZy8OUDQSiIGSQZrCP4lcfuCzwpawEDkQCe+ZPqmXt3ygcREXDPHNRSHgPW0vDdRO7aOYkmESSQ1+rVsoNxUXxtnFDBAfs0susxiSotvE3M6OqGHXNqKoR6nrsixEqUhohVSNwPQKzz4AgLXMhBjv6NvvC2c4wLI1rC9fr2+XymPcuW7QUWZRoRSKO7QPzlepVAeASK5OvyKMZmtWvoxX+lOoXcWljB+Bdw12WoOWso2euqhKqqsZ4PEZdj0Bsml2bLJmAZEvUAh6J8ECZrZbNzjYQG+kPfywvEdiEsMWjT+dM+5xuG/+6sF25BS9FYGEgLN27neSuVxQhcbE52sW3l4C/C9ww8nMR+X7Udm/Ulc00G4/HmEwmqKoKxBU41a5SA4SqIk7qrm842NG3+dakAAqDYPxpfxGUwj5Iyz60DIN53HYKTevJbf/CvXU8/CtDg5Stc6IkkX3gGtDsK3UOQ4g2evUahpWF67rCwmQB48kYC+vGqEe1U2IM4gSFgTdxKusQY9lZBzuaNifbEEM63LOiU9XCEjVYcLoBXtHecQoF1p4BMRa1y174Tu2YoihRKxDrxod1J9hoFDHIwgd2D1u2IQGUkZJ1KE8mY6xfvw7jyRijcWWeNTTJCoiHGJySP4Gc1RgKFatmc4z1lyILLDFkp0zaj2kNtDlnm4bj+/YVZJagWc+bKbtQjq0eD9v37AlfQtvFYJ61PX9Xd+EHKtWzlJKNRVUUAFuoQBjXNSYTCxPG4xpVXYESockNJLfDTSK8UHKdLxSZEFKjwVbBVuR5QwjTFegotCi5AEUWLV43+NoSWrTamdZvdjS0fa+L9nzxnwM0QNheZAviBAZXhFRVvlCg0WpMbFxtlTAaVZiMRhiPJxiPx6gquw7rVXO6zWm3OG5W8QZO88wt5zbY0ba5wBurVUIFxAr4Mk8iYvGl9qtoXRCWGDRZBzIU0GwezcBIvTi5f3LyRz+3MsuOBy1shFgoERMihRNSNSqt9ARCzQmjyqbwjEY1xqMadVW7dkP9PTQwKWSsIORFkYjTQciq5WYabHVsrrBBcwZyA9UGWh77xvCKWEdE0zQHLQGHmec0jaw5rRD5tFwtUYzyA4z+ysbpxoRInxiZKu8Kplhc0I4f8k1JdfG8UZkbc426SqjrhFFdYeQUGLsWuQh64hFBMVcivDBKtU4Jrh8ebDVsdvA2ApJsZd+ArAhEM7JkNGLNjV3VWPerDNYD+erwWooSQBtH27zd7mvqMx+oE6sacKs6FfBi2WT0BK2M4kqcwK5RGKcxRlWNujZqLMVTQAVZsrW6N+rtS0Er2M0mGrJNL+0Bw6rvq2hzhA223gQoRC7maeOryYLsla5ocV9yhI52sQUyEEUIeEjAPQoNZJxCF7zsmoPEVQEzoQ/eVFXQNAI42ToWzEipwmg0xrgeYVSxAVcUOU+NxsuARUWmZhNnHOBsg7EOliiKT7IcwobVszkWzrZW8W5cO51Oi6fN/qgNMXpX/NUqwdzTEjp/9K46qx/7BoBjQcJ2uDSb1oAS6qourwd4U0ogrpBTBaLKmAZOXoQYo6oqDxMAdW9r7yOUaKW1FC1tRw7cSDKtFD0wZatnM4O3aWwciGjudeGKCBoRaxVX7SRQB5Ewers6nCKLRA0I1oAAYc/mo9QLVCRIhDKuP7xtVVU+6j/1kjcbLl0BzIhB1bZIdg0gQcHIjUJzA8kNmiaXNndboSihC1r4FYsqhL26BhcdDR0Vq2ZzzW3IkqHIPa9r5eAoUkihlboJW8u9GlSl/MFtjbT4ntTa0G3NN5M/VkyoSZASABeGMxOqui7g7YYT8SVqx24XWLFJlDlbwYSzAp2lBuwGgt9gcDmnFGpPYPPUTGTUFmUGMfrq2ezglVxCh/C62okP+klaTCQnVKF5CCZByZeeMMGLwkYwBcNA1HrsRIS6qlDBPa8nXakCuKpMe7CkcqaqyNkdPCWoeu+ZKhppkHO2UU1qixCK2vkTxxoWGUKmOhNRKBMygEYX0fhqQclXmAcwhA2raLOHDdMGoo1n5C2jAKIi1gG6RYYoKpTE3EaVqlXTmCoop3blNqq8uyGXGyDE3zUn97gMF3n1CxTUinBCTaZk454gNrXSfb57ZRs40sovPY7VkCqbbljI+NxGBFN/76rRjDnYattcYUOTG+TOipY5ZxCzj+oPLS2VIgIB3vjVMglECZJsianCECCmo8eMXgtGgjWoK0aKDooEKLUdvLl06MSawT6YGq6H8MmSoopYzmpp+35XwdbkjEay3QxkT5RpM8VUp2hy0wsVXqktabCjY7NTZRJjQaM06myAqK3vGyXUIreK78SBm1wbS+2A6aDKosxK5MwAgUldHF4Zpxv0GtkyWtTR0hobHMmfefe+Si0AnNsqmidcZShJd0iJ5iJ3bHK2+Wa66KFTW4CJxHGw1bG5wAu1wc2tjjUUXjH4mXr6AgA2xp8iprWkyfgGr1jBXqfEpVScmJFI7d9YctV4Ld/TJ0ZSCCLaxQSJfG1jF57HlUZTpfgiK9mHi9hqQO0CKlnEBl2zzQtumgbT6RSLslha92O2WiSMg62OzcHzivO3wdN63OnClC5glym8EIwDu9iFyrGiU8G4WQsN6pR8lcto3WnZCaWQ83QHWfv4aUrl9cijbE+fyoOObqLbCaKELIqmcQlngrcyKZrpFNPpFFOZlng/JmaKZAxRw+rZnOCNNdIMImWtiSVgfaXvC7HvOlwjBBjkXG1b2q2QSkgBQMW8rHtaIv8ZnUTL08NIyNqwpWjZeuVq8aQTHuo0ucF+By/DwpssgqkzK1NpINIOogbglbnVXxXnjWpzdVIUOorgYvT++mll3HRHKUb+6LZ/jXsl8vm6KXlXrlXLYtXLihPKSkLw/RSmZCuLr8C9qTMciCSse+N0pO5+/0jOtrCehwjk1zudNlicTs2L+9K0UxcaWZjQJmdRzesme4MdfVvRlEhR45SUI3PnUgQAglXoelxfzopqICbgEINcOGN6206xgQiETnOnslXbfCqvksWt1rUsJVkLRRoVxVtulQcep6saczKdTg28voGJihowJ0jTQODg7U736SSAB5VuDnZUbfaJOczGKgClLBrAZTYVt+ka+l0WvZCCKiixnZTIwEupKL+6XRDoVOqIYCvvIPjVUKQt1RlQVCcAUogfLkZiAyY0bzRjMbceFUBZ/1iEEE0+7RptANRWIlLKfokDcFfbZl8427Nq1bZ3rQ0X+slZt4DQ0xtwgsbST5RAVWXg9YQNQJkvFiC0MLf16LHAX18v3NH/hspSGSIKYimJX3DVU19MJYoO5X2pgjgVj9oNC8jpN6XYftZPbrDXykgP1aI72GCvYxvqnIOtWRvAO9iatQG8g61ZG8A72Jq1AbyDrVkbwDvYmrUBvIOtWRvAO9iatQG8g61Z+/92LX/ytKbPdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 200x100 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' 5. 데이터 확인하기 (2) '''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(BATCH_SIZE * pltsize, pltsize))\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    plt.subplot(1, BATCH_SIZE, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
    "    plt.title('Class: ' + str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc11d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 6. 불러온 특정 모델에 대해 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train() # 모델을 학습 상태로 지정\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        label = list(map(int, label))\n",
    "        label = torch.Tensor(label)\n",
    "        image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        optimizer.zero_grad() # 기존 할당되어 있던 gradient 값 초기화\n",
    "        output = model(image) # Forward propagation\n",
    "        loss = criterion(output, label.long()) # loss 계산\n",
    "        loss.backward() # Backpropagation을 통해 계산된 gradient 값을 각 파라미터에 할당\n",
    "        optimizer.step() # 파라미터 업데이트\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                  Epoch, batch_idx * len(image),\n",
    "                  len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                  loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c1f5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 7. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval() # 모델을 평가 상태로 지정\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # 평가하는 단계에서 gradient를 통해 파라미터 값이 업데이트되는 현상을 방지\n",
    "        for image, label in test_loader:\n",
    "            label = list(map(int, label))\n",
    "            label = torch.Tensor(label)\n",
    "            image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            output = model(image) # Forward propagation\n",
    "            test_loss += criterion(output, label.long()).item() # loss 누적\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item() \n",
    "            \n",
    "    test_loss /= len(test_loader.dataset) # 평균 loss 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset) # 정확도 계산\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "922c4332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1231,  0.0724,  0.0723,  ...,  0.2914,  0.1601,  0.1923],\n",
      "        [ 0.1293,  0.0940,  0.0830,  ...,  0.0718,  0.2748,  0.0245]],\n",
      "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "ReXNetV1(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6()\n",
      "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): Conv2d(96, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(27, 162, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(162, 162, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=162, bias=False)\n",
      "        (4): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6()\n",
      "        (6): Conv2d(162, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(38, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(228, 228, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=228, bias=False)\n",
      "        (4): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(228, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(19, 228, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(228, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(50, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=300, bias=False)\n",
      "        (4): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(300, 25, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(25, 300, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(300, 61, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(61, 366, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(366, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(366, 366, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=366, bias=False)\n",
      "        (4): BatchNorm2d(366, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(366, 30, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(30, 366, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(366, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
      "        (4): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(432, 36, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(36, 432, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(432, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(84, 504, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(504, 504, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=504, bias=False)\n",
      "        (4): BatchNorm2d(504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(504, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(42, 504, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(504, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(95, 570, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(570, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(570, 570, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=570, bias=False)\n",
      "        (4): BatchNorm2d(570, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(570, 47, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(47, 570, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(570, 106, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(106, 636, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(636, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(636, 636, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=636, bias=False)\n",
      "        (4): BatchNorm2d(636, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(636, 53, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(53, 636, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(636, 117, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(117, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(117, 702, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(702, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(702, 702, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=702, bias=False)\n",
      "        (4): BatchNorm2d(702, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(702, 58, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(58, 702, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(702, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=768, bias=False)\n",
      "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(768, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(140, 840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(840, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(840, 840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=840, bias=False)\n",
      "        (4): BatchNorm2d(840, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(840, 70, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(70, 840, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(840, 151, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(151, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(151, 906, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(906, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(906, 906, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=906, bias=False)\n",
      "        (4): BatchNorm2d(906, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(906, 75, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(75, 906, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(906, 162, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(162, 972, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(972, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(972, 972, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=972, bias=False)\n",
      "        (4): BatchNorm2d(972, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(972, 81, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(81, 972, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(972, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): LinearBottleneck(\n",
      "      (out): Sequential(\n",
      "        (0): Conv2d(174, 1044, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(1044, 1044, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1044, bias=False)\n",
      "        (4): BatchNorm2d(1044, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): SE(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Conv2d(1044, 87, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(87, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(87, 1044, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (6): ReLU6()\n",
      "        (7): Conv2d(1044, 185, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (8): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): Conv2d(185, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (20): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (21): SiLU()\n",
      "    (22): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Conv2d(1280, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "if MODEL == 'AlexNet':\n",
    "    model = models.alexnet(pretrained=False)\n",
    "    model._modules['classifier']._modules['6'] = nn.Linear(4096, 2, bias=True)\n",
    "elif MODEL == 'ResNet18':\n",
    "    model = models.resnet18(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'ResNet34':\n",
    "    model = models.resnet34(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'ResNet50':\n",
    "    model = models.resnet50(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'ResNet101':\n",
    "    model = models.resnet101(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'RexNet': # BATCH_SIZE 1은 에러남\n",
    "    model = rexnetv1.ReXNetV1(width_mult=1.0).cuda()\n",
    "    print(model(torch.randn(BATCH_SIZE, 3, 224, 224).cuda())) \n",
    "    \n",
    "init_model = copy.deepcopy(model)\n",
    "print(init_model)\n",
    "\n",
    "#for children in model.classifier.children():\n",
    "#    if isinstance(children, nn.Linear):\n",
    "#        if children.out_features == 1000:\n",
    "#            print(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d06b78dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------    For  fold1  dataset    ------------------\n",
      "Train Epoch: 1 [0/1877(0%)]\tTrain Loss: 6.801125\n",
      "Train Epoch: 1 [400/1877(21%)]\tTrain Loss: 0.534126\n",
      "Train Epoch: 1 [800/1877(43%)]\tTrain Loss: 0.737911\n",
      "Train Epoch: 1 [1200/1877(64%)]\tTrain Loss: 0.738293\n",
      "Train Epoch: 1 [1600/1877(85%)]\tTrain Loss: 0.472382\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 1], \tTest Loss: 1.0246, \tTest Accuracy: 55.79 %\n",
      " \n",
      "Train Epoch: 2 [0/1877(0%)]\tTrain Loss: 1.058674\n",
      "Train Epoch: 2 [400/1877(21%)]\tTrain Loss: 0.668402\n",
      "Train Epoch: 2 [800/1877(43%)]\tTrain Loss: 0.613803\n",
      "Train Epoch: 2 [1200/1877(64%)]\tTrain Loss: 0.952016\n",
      "Train Epoch: 2 [1600/1877(85%)]\tTrain Loss: 0.752922\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 2], \tTest Loss: 0.6194, \tTest Accuracy: 57.51 %\n",
      " \n",
      "Train Epoch: 3 [0/1877(0%)]\tTrain Loss: 0.141874\n",
      "Train Epoch: 3 [400/1877(21%)]\tTrain Loss: 0.685110\n",
      "Train Epoch: 3 [800/1877(43%)]\tTrain Loss: 0.091813\n",
      "Train Epoch: 3 [1200/1877(64%)]\tTrain Loss: 0.930350\n",
      "Train Epoch: 3 [1600/1877(85%)]\tTrain Loss: 0.512550\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 3], \tTest Loss: 0.5216, \tTest Accuracy: 79.40 %\n",
      " \n",
      "Train Epoch: 4 [0/1877(0%)]\tTrain Loss: 0.114220\n",
      "Train Epoch: 4 [400/1877(21%)]\tTrain Loss: 0.673330\n",
      "Train Epoch: 4 [800/1877(43%)]\tTrain Loss: 0.994747\n",
      "Train Epoch: 4 [1200/1877(64%)]\tTrain Loss: 0.846963\n",
      "Train Epoch: 4 [1600/1877(85%)]\tTrain Loss: 0.832158\n",
      "\n",
      "EPOCH: 4], \tTest Loss: 0.3256, \tTest Accuracy: 79.40 %\n",
      " \n",
      "Train Epoch: 5 [0/1877(0%)]\tTrain Loss: 0.594629\n",
      "Train Epoch: 5 [400/1877(21%)]\tTrain Loss: 0.430290\n",
      "Train Epoch: 5 [800/1877(43%)]\tTrain Loss: 0.516543\n",
      "Train Epoch: 5 [1200/1877(64%)]\tTrain Loss: 0.050551\n",
      "Train Epoch: 5 [1600/1877(85%)]\tTrain Loss: 0.915359\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 5], \tTest Loss: 0.1468, \tTest Accuracy: 87.55 %\n",
      " \n",
      "Train Epoch: 6 [0/1877(0%)]\tTrain Loss: 0.104675\n",
      "Train Epoch: 6 [400/1877(21%)]\tTrain Loss: 0.064653\n",
      "Train Epoch: 6 [800/1877(43%)]\tTrain Loss: 0.124814\n",
      "Train Epoch: 6 [1200/1877(64%)]\tTrain Loss: 0.539307\n",
      "Train Epoch: 6 [1600/1877(85%)]\tTrain Loss: 1.390625\n",
      "\n",
      "EPOCH: 6], \tTest Loss: 0.2411, \tTest Accuracy: 80.69 %\n",
      " \n",
      "Train Epoch: 7 [0/1877(0%)]\tTrain Loss: 1.513000\n",
      "Train Epoch: 7 [400/1877(21%)]\tTrain Loss: 0.577556\n",
      "Train Epoch: 7 [800/1877(43%)]\tTrain Loss: 0.046648\n",
      "Train Epoch: 7 [1200/1877(64%)]\tTrain Loss: 0.469047\n",
      "Train Epoch: 7 [1600/1877(85%)]\tTrain Loss: 0.062010\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 7], \tTest Loss: 0.1116, \tTest Accuracy: 94.85 %\n",
      " \n",
      "Train Epoch: 8 [0/1877(0%)]\tTrain Loss: 0.352592\n",
      "Train Epoch: 8 [400/1877(21%)]\tTrain Loss: 0.682042\n",
      "Train Epoch: 8 [800/1877(43%)]\tTrain Loss: 0.292702\n",
      "Train Epoch: 8 [1200/1877(64%)]\tTrain Loss: 0.006013\n",
      "Train Epoch: 8 [1600/1877(85%)]\tTrain Loss: 0.909359\n",
      "\n",
      "EPOCH: 8], \tTest Loss: 0.1630, \tTest Accuracy: 86.27 %\n",
      " \n",
      "Train Epoch: 9 [0/1877(0%)]\tTrain Loss: 0.150202\n",
      "Train Epoch: 9 [400/1877(21%)]\tTrain Loss: 0.156222\n",
      "Train Epoch: 9 [800/1877(43%)]\tTrain Loss: 0.481570\n",
      "Train Epoch: 9 [1200/1877(64%)]\tTrain Loss: 0.992300\n",
      "Train Epoch: 9 [1600/1877(85%)]\tTrain Loss: 1.172095\n",
      "\n",
      "EPOCH: 9], \tTest Loss: 0.2297, \tTest Accuracy: 85.41 %\n",
      " \n",
      "Train Epoch: 10 [0/1877(0%)]\tTrain Loss: 0.030307\n",
      "Train Epoch: 10 [400/1877(21%)]\tTrain Loss: 0.067360\n",
      "Train Epoch: 10 [800/1877(43%)]\tTrain Loss: 0.080326\n",
      "Train Epoch: 10 [1200/1877(64%)]\tTrain Loss: 0.073086\n",
      "Train Epoch: 10 [1600/1877(85%)]\tTrain Loss: 0.923709\n",
      "\n",
      "EPOCH: 10], \tTest Loss: 0.1734, \tTest Accuracy: 91.85 %\n",
      " \n",
      "------------------    Best Model at Epoch 7 Saved    ------------------\n",
      "------------------    For  fold2  dataset    ------------------\n",
      "Train Epoch: 1 [0/1880(0%)]\tTrain Loss: 6.773240\n",
      "Train Epoch: 1 [400/1880(21%)]\tTrain Loss: 0.208729\n",
      "Train Epoch: 1 [800/1880(43%)]\tTrain Loss: 0.616711\n",
      "Train Epoch: 1 [1200/1880(64%)]\tTrain Loss: 0.564957\n",
      "Train Epoch: 1 [1600/1880(85%)]\tTrain Loss: 0.746118\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 1], \tTest Loss: 0.7163, \tTest Accuracy: 70.19 %\n",
      " \n",
      "Train Epoch: 2 [0/1880(0%)]\tTrain Loss: 0.106822\n",
      "Train Epoch: 2 [400/1880(21%)]\tTrain Loss: 0.348614\n",
      "Train Epoch: 2 [800/1880(43%)]\tTrain Loss: 0.931239\n",
      "Train Epoch: 2 [1200/1880(64%)]\tTrain Loss: 0.201164\n",
      "Train Epoch: 2 [1600/1880(85%)]\tTrain Loss: 1.114322\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 2], \tTest Loss: 0.8240, \tTest Accuracy: 77.11 %\n",
      " \n",
      "Train Epoch: 3 [0/1880(0%)]\tTrain Loss: 0.190203\n",
      "Train Epoch: 3 [400/1880(21%)]\tTrain Loss: 1.475253\n",
      "Train Epoch: 3 [800/1880(43%)]\tTrain Loss: 0.554399\n",
      "Train Epoch: 3 [1200/1880(64%)]\tTrain Loss: 0.330196\n",
      "Train Epoch: 3 [1600/1880(85%)]\tTrain Loss: 1.210224\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 3], \tTest Loss: 0.2482, \tTest Accuracy: 82.72 %\n",
      " \n",
      "Train Epoch: 4 [0/1880(0%)]\tTrain Loss: 0.342175\n",
      "Train Epoch: 4 [400/1880(21%)]\tTrain Loss: 0.743370\n",
      "Train Epoch: 4 [800/1880(43%)]\tTrain Loss: 0.094280\n",
      "Train Epoch: 4 [1200/1880(64%)]\tTrain Loss: 0.821463\n",
      "Train Epoch: 4 [1600/1880(85%)]\tTrain Loss: 0.623873\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 4], \tTest Loss: 0.2932, \tTest Accuracy: 84.88 %\n",
      " \n",
      "Train Epoch: 5 [0/1880(0%)]\tTrain Loss: 1.046099\n",
      "Train Epoch: 5 [400/1880(21%)]\tTrain Loss: 0.153089\n",
      "Train Epoch: 5 [800/1880(43%)]\tTrain Loss: 0.321122\n",
      "Train Epoch: 5 [1200/1880(64%)]\tTrain Loss: 0.133289\n",
      "Train Epoch: 5 [1600/1880(85%)]\tTrain Loss: 0.371582\n",
      "\n",
      "EPOCH: 5], \tTest Loss: 0.3495, \tTest Accuracy: 81.86 %\n",
      " \n",
      "Train Epoch: 6 [0/1880(0%)]\tTrain Loss: 1.064793\n",
      "Train Epoch: 6 [400/1880(21%)]\tTrain Loss: 0.047471\n",
      "Train Epoch: 6 [800/1880(43%)]\tTrain Loss: 1.124282\n",
      "Train Epoch: 6 [1200/1880(64%)]\tTrain Loss: 0.122974\n",
      "Train Epoch: 6 [1600/1880(85%)]\tTrain Loss: 0.048600\n",
      "\n",
      "EPOCH: 6], \tTest Loss: 0.9376, \tTest Accuracy: 76.03 %\n",
      " \n",
      "Train Epoch: 7 [0/1880(0%)]\tTrain Loss: 0.571828\n",
      "Train Epoch: 7 [400/1880(21%)]\tTrain Loss: 0.107242\n",
      "Train Epoch: 7 [800/1880(43%)]\tTrain Loss: 0.614730\n",
      "Train Epoch: 7 [1200/1880(64%)]\tTrain Loss: 0.043315\n",
      "Train Epoch: 7 [1600/1880(85%)]\tTrain Loss: 0.902274\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 7], \tTest Loss: 0.1657, \tTest Accuracy: 87.47 %\n",
      " \n",
      "Train Epoch: 8 [0/1880(0%)]\tTrain Loss: 0.430516\n",
      "Train Epoch: 8 [400/1880(21%)]\tTrain Loss: 0.894116\n",
      "Train Epoch: 8 [800/1880(43%)]\tTrain Loss: 0.671118\n",
      "Train Epoch: 8 [1200/1880(64%)]\tTrain Loss: 1.083032\n",
      "Train Epoch: 8 [1600/1880(85%)]\tTrain Loss: 0.292443\n",
      "\n",
      "EPOCH: 8], \tTest Loss: 0.1582, \tTest Accuracy: 83.15 %\n",
      " \n",
      "Train Epoch: 9 [0/1880(0%)]\tTrain Loss: 0.695593\n",
      "Train Epoch: 9 [400/1880(21%)]\tTrain Loss: 0.712767\n",
      "Train Epoch: 9 [800/1880(43%)]\tTrain Loss: 0.291095\n",
      "Train Epoch: 9 [1200/1880(64%)]\tTrain Loss: 0.068917\n",
      "Train Epoch: 9 [1600/1880(85%)]\tTrain Loss: 0.914807\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 9], \tTest Loss: 0.0991, \tTest Accuracy: 93.74 %\n",
      " \n",
      "Train Epoch: 10 [0/1880(0%)]\tTrain Loss: 0.027497\n",
      "Train Epoch: 10 [400/1880(21%)]\tTrain Loss: 0.223196\n",
      "Train Epoch: 10 [800/1880(43%)]\tTrain Loss: 0.066236\n",
      "Train Epoch: 10 [1200/1880(64%)]\tTrain Loss: 0.179349\n",
      "Train Epoch: 10 [1600/1880(85%)]\tTrain Loss: 1.110943\n",
      "\n",
      "EPOCH: 10], \tTest Loss: 0.1376, \tTest Accuracy: 90.93 %\n",
      " \n",
      "------------------    Best Model at Epoch 9 Saved    ------------------\n",
      "------------------    For  fold3  dataset    ------------------\n",
      "Train Epoch: 1 [0/1878(0%)]\tTrain Loss: 6.795642\n",
      "Train Epoch: 1 [400/1878(21%)]\tTrain Loss: 0.117585\n",
      "Train Epoch: 1 [800/1878(43%)]\tTrain Loss: 0.840772\n",
      "Train Epoch: 1 [1200/1878(64%)]\tTrain Loss: 0.365679\n",
      "Train Epoch: 1 [1600/1878(85%)]\tTrain Loss: 0.426930\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 1], \tTest Loss: 0.6926, \tTest Accuracy: 70.54 %\n",
      " \n",
      "Train Epoch: 2 [0/1878(0%)]\tTrain Loss: 0.558602\n",
      "Train Epoch: 2 [400/1878(21%)]\tTrain Loss: 0.082452\n",
      "Train Epoch: 2 [800/1878(43%)]\tTrain Loss: 0.081784\n",
      "Train Epoch: 2 [1200/1878(64%)]\tTrain Loss: 1.420313\n",
      "Train Epoch: 2 [1600/1878(85%)]\tTrain Loss: 0.082675\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 2], \tTest Loss: 0.7505, \tTest Accuracy: 80.65 %\n",
      " \n",
      "Train Epoch: 3 [0/1878(0%)]\tTrain Loss: 0.129717\n",
      "Train Epoch: 3 [400/1878(21%)]\tTrain Loss: 0.269335\n",
      "Train Epoch: 3 [800/1878(43%)]\tTrain Loss: 1.247086\n",
      "Train Epoch: 3 [1200/1878(64%)]\tTrain Loss: 0.176616\n",
      "Train Epoch: 3 [1600/1878(85%)]\tTrain Loss: 0.311470\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 3], \tTest Loss: 0.4211, \tTest Accuracy: 82.37 %\n",
      " \n",
      "Train Epoch: 4 [0/1878(0%)]\tTrain Loss: 0.711173\n",
      "Train Epoch: 4 [400/1878(21%)]\tTrain Loss: 0.109978\n",
      "Train Epoch: 4 [800/1878(43%)]\tTrain Loss: 0.641865\n",
      "Train Epoch: 4 [1200/1878(64%)]\tTrain Loss: 0.454305\n",
      "Train Epoch: 4 [1600/1878(85%)]\tTrain Loss: 0.949188\n",
      "\n",
      "EPOCH: 4], \tTest Loss: 1.0952, \tTest Accuracy: 72.26 %\n",
      " \n",
      "Train Epoch: 5 [0/1878(0%)]\tTrain Loss: 0.091188\n",
      "Train Epoch: 5 [400/1878(21%)]\tTrain Loss: 0.046743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [800/1878(43%)]\tTrain Loss: 0.596341\n",
      "Train Epoch: 5 [1200/1878(64%)]\tTrain Loss: 0.258023\n",
      "Train Epoch: 5 [1600/1878(85%)]\tTrain Loss: 0.609317\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 5], \tTest Loss: 0.2632, \tTest Accuracy: 88.60 %\n",
      " \n",
      "Train Epoch: 6 [0/1878(0%)]\tTrain Loss: 0.040664\n",
      "Train Epoch: 6 [400/1878(21%)]\tTrain Loss: 0.737749\n",
      "Train Epoch: 6 [800/1878(43%)]\tTrain Loss: 0.266073\n",
      "Train Epoch: 6 [1200/1878(64%)]\tTrain Loss: 0.242428\n",
      "Train Epoch: 6 [1600/1878(85%)]\tTrain Loss: 0.504457\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 6], \tTest Loss: 0.2312, \tTest Accuracy: 90.75 %\n",
      " \n",
      "Train Epoch: 7 [0/1878(0%)]\tTrain Loss: 0.734522\n",
      "Train Epoch: 7 [400/1878(21%)]\tTrain Loss: 0.390748\n",
      "Train Epoch: 7 [800/1878(43%)]\tTrain Loss: 0.050801\n",
      "Train Epoch: 7 [1200/1878(64%)]\tTrain Loss: 0.729975\n",
      "Train Epoch: 7 [1600/1878(85%)]\tTrain Loss: 1.227333\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 7], \tTest Loss: 0.1562, \tTest Accuracy: 94.19 %\n",
      " \n",
      "Train Epoch: 8 [0/1878(0%)]\tTrain Loss: 0.608582\n",
      "Train Epoch: 8 [400/1878(21%)]\tTrain Loss: 0.788761\n",
      "Train Epoch: 8 [800/1878(43%)]\tTrain Loss: 0.761834\n",
      "Train Epoch: 8 [1200/1878(64%)]\tTrain Loss: 0.618993\n",
      "Train Epoch: 8 [1600/1878(85%)]\tTrain Loss: 0.905749\n",
      "\n",
      "EPOCH: 8], \tTest Loss: 0.1321, \tTest Accuracy: 92.69 %\n",
      " \n",
      "Train Epoch: 9 [0/1878(0%)]\tTrain Loss: 0.086856\n",
      "Train Epoch: 9 [400/1878(21%)]\tTrain Loss: 0.129835\n",
      "Train Epoch: 9 [800/1878(43%)]\tTrain Loss: 1.102849\n",
      "Train Epoch: 9 [1200/1878(64%)]\tTrain Loss: 0.890011\n",
      "Train Epoch: 9 [1600/1878(85%)]\tTrain Loss: 0.650085\n",
      "\n",
      "EPOCH: 9], \tTest Loss: 0.1875, \tTest Accuracy: 90.54 %\n",
      " \n",
      "Train Epoch: 10 [0/1878(0%)]\tTrain Loss: 0.293048\n",
      "Train Epoch: 10 [400/1878(21%)]\tTrain Loss: 0.131512\n",
      "Train Epoch: 10 [800/1878(43%)]\tTrain Loss: 0.044231\n",
      "Train Epoch: 10 [1200/1878(64%)]\tTrain Loss: 0.030298\n",
      "Train Epoch: 10 [1600/1878(85%)]\tTrain Loss: 0.723313\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 10], \tTest Loss: 0.0887, \tTest Accuracy: 94.84 %\n",
      " \n",
      "------------------    Best Model at Epoch 10 Saved    ------------------\n",
      "------------------    For  fold4  dataset    ------------------\n",
      "Train Epoch: 1 [0/1870(0%)]\tTrain Loss: 6.778981\n",
      "Train Epoch: 1 [400/1870(21%)]\tTrain Loss: 0.217565\n",
      "Train Epoch: 1 [800/1870(43%)]\tTrain Loss: 0.198031\n",
      "Train Epoch: 1 [1200/1870(64%)]\tTrain Loss: 1.049593\n",
      "Train Epoch: 1 [1600/1870(86%)]\tTrain Loss: 0.242296\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 1], \tTest Loss: 0.5738, \tTest Accuracy: 66.60 %\n",
      " \n",
      "Train Epoch: 2 [0/1870(0%)]\tTrain Loss: 0.198034\n",
      "Train Epoch: 2 [400/1870(21%)]\tTrain Loss: 0.783379\n",
      "Train Epoch: 2 [800/1870(43%)]\tTrain Loss: 0.553562\n",
      "Train Epoch: 2 [1200/1870(64%)]\tTrain Loss: 0.361591\n",
      "Train Epoch: 2 [1600/1870(86%)]\tTrain Loss: 0.600216\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 2], \tTest Loss: 0.5079, \tTest Accuracy: 78.86 %\n",
      " \n",
      "Train Epoch: 3 [0/1870(0%)]\tTrain Loss: 0.481788\n",
      "Train Epoch: 3 [400/1870(21%)]\tTrain Loss: 0.238811\n",
      "Train Epoch: 3 [800/1870(43%)]\tTrain Loss: 0.785544\n",
      "Train Epoch: 3 [1200/1870(64%)]\tTrain Loss: 0.243566\n",
      "Train Epoch: 3 [1600/1870(86%)]\tTrain Loss: 0.108292\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 3], \tTest Loss: 0.4663, \tTest Accuracy: 80.34 %\n",
      " \n",
      "Train Epoch: 4 [0/1870(0%)]\tTrain Loss: 0.069847\n",
      "Train Epoch: 4 [400/1870(21%)]\tTrain Loss: 0.892874\n",
      "Train Epoch: 4 [800/1870(43%)]\tTrain Loss: 0.784297\n",
      "Train Epoch: 4 [1200/1870(64%)]\tTrain Loss: 0.108432\n",
      "Train Epoch: 4 [1600/1870(86%)]\tTrain Loss: 0.642331\n",
      "\n",
      "EPOCH: 4], \tTest Loss: 0.8261, \tTest Accuracy: 71.67 %\n",
      " \n",
      "Train Epoch: 5 [0/1870(0%)]\tTrain Loss: 0.082591\n",
      "Train Epoch: 5 [400/1870(21%)]\tTrain Loss: 0.129397\n",
      "Train Epoch: 5 [800/1870(43%)]\tTrain Loss: 0.919439\n",
      "Train Epoch: 5 [1200/1870(64%)]\tTrain Loss: 0.222755\n",
      "Train Epoch: 5 [1600/1870(86%)]\tTrain Loss: 1.091681\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 5], \tTest Loss: 0.2265, \tTest Accuracy: 85.62 %\n",
      " \n",
      "Train Epoch: 6 [0/1870(0%)]\tTrain Loss: 0.114510\n",
      "Train Epoch: 6 [400/1870(21%)]\tTrain Loss: 0.871321\n",
      "Train Epoch: 6 [800/1870(43%)]\tTrain Loss: 0.536420\n",
      "Train Epoch: 6 [1200/1870(64%)]\tTrain Loss: 0.042858\n",
      "Train Epoch: 6 [1600/1870(86%)]\tTrain Loss: 0.857449\n",
      "\n",
      "EPOCH: 6], \tTest Loss: 0.6545, \tTest Accuracy: 59.83 %\n",
      " \n",
      "Train Epoch: 7 [0/1870(0%)]\tTrain Loss: 0.054170\n",
      "Train Epoch: 7 [400/1870(21%)]\tTrain Loss: 0.089025\n",
      "Train Epoch: 7 [800/1870(43%)]\tTrain Loss: 0.719722\n",
      "Train Epoch: 7 [1200/1870(64%)]\tTrain Loss: 0.039307\n",
      "Train Epoch: 7 [1600/1870(86%)]\tTrain Loss: 0.389041\n",
      "\n",
      "EPOCH: 7], \tTest Loss: 0.5133, \tTest Accuracy: 83.93 %\n",
      " \n",
      "Train Epoch: 8 [0/1870(0%)]\tTrain Loss: 0.708424\n",
      "Train Epoch: 8 [400/1870(21%)]\tTrain Loss: 0.535173\n",
      "Train Epoch: 8 [800/1870(43%)]\tTrain Loss: 0.095450\n",
      "Train Epoch: 8 [1200/1870(64%)]\tTrain Loss: 0.028352\n",
      "Train Epoch: 8 [1600/1870(86%)]\tTrain Loss: 0.785473\n",
      "\n",
      "EPOCH: 8], \tTest Loss: 0.6041, \tTest Accuracy: 81.82 %\n",
      " \n",
      "Train Epoch: 9 [0/1870(0%)]\tTrain Loss: 0.725940\n",
      "Train Epoch: 9 [400/1870(21%)]\tTrain Loss: 0.173616\n",
      "Train Epoch: 9 [800/1870(43%)]\tTrain Loss: 1.214336\n",
      "Train Epoch: 9 [1200/1870(64%)]\tTrain Loss: 0.090275\n",
      "Train Epoch: 9 [1600/1870(86%)]\tTrain Loss: 0.312421\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 9], \tTest Loss: 0.2429, \tTest Accuracy: 87.53 %\n",
      " \n",
      "Train Epoch: 10 [0/1870(0%)]\tTrain Loss: 0.152670\n",
      "Train Epoch: 10 [400/1870(21%)]\tTrain Loss: 1.986456\n",
      "Train Epoch: 10 [800/1870(43%)]\tTrain Loss: 0.306019\n",
      "Train Epoch: 10 [1200/1870(64%)]\tTrain Loss: 0.126843\n",
      "Train Epoch: 10 [1600/1870(86%)]\tTrain Loss: 0.030371\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 10], \tTest Loss: 0.0990, \tTest Accuracy: 93.45 %\n",
      " \n",
      "------------------    Best Model at Epoch 10 Saved    ------------------\n",
      "------------------    For  fold5  dataset    ------------------\n",
      "Train Epoch: 1 [0/1867(0%)]\tTrain Loss: 6.900931\n",
      "Train Epoch: 1 [400/1867(21%)]\tTrain Loss: 0.818381\n",
      "Train Epoch: 1 [800/1867(43%)]\tTrain Loss: 0.690158\n",
      "Train Epoch: 1 [1200/1867(64%)]\tTrain Loss: 0.293924\n",
      "Train Epoch: 1 [1600/1867(86%)]\tTrain Loss: 0.082681\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 1], \tTest Loss: 0.4319, \tTest Accuracy: 79.83 %\n",
      " \n",
      "Train Epoch: 2 [0/1867(0%)]\tTrain Loss: 1.157398\n",
      "Train Epoch: 2 [400/1867(21%)]\tTrain Loss: 1.004346\n",
      "Train Epoch: 2 [800/1867(43%)]\tTrain Loss: 0.346950\n",
      "Train Epoch: 2 [1200/1867(64%)]\tTrain Loss: 1.023936\n",
      "Train Epoch: 2 [1600/1867(86%)]\tTrain Loss: 0.588811\n",
      "\n",
      "EPOCH: 2], \tTest Loss: 0.2587, \tTest Accuracy: 79.20 %\n",
      " \n",
      "Train Epoch: 3 [0/1867(0%)]\tTrain Loss: 0.605029\n",
      "Train Epoch: 3 [400/1867(21%)]\tTrain Loss: 0.452346\n",
      "Train Epoch: 3 [800/1867(43%)]\tTrain Loss: 0.023462\n",
      "Train Epoch: 3 [1200/1867(64%)]\tTrain Loss: 0.150731\n",
      "Train Epoch: 3 [1600/1867(86%)]\tTrain Loss: 1.442539\n",
      "\n",
      "EPOCH: 3], \tTest Loss: 0.2723, \tTest Accuracy: 79.41 %\n",
      " \n",
      "Train Epoch: 4 [0/1867(0%)]\tTrain Loss: 1.310518\n",
      "Train Epoch: 4 [400/1867(21%)]\tTrain Loss: 1.081741\n",
      "Train Epoch: 4 [800/1867(43%)]\tTrain Loss: 1.157427\n",
      "Train Epoch: 4 [1200/1867(64%)]\tTrain Loss: 0.211492\n",
      "Train Epoch: 4 [1600/1867(86%)]\tTrain Loss: 0.078020\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 4], \tTest Loss: 0.1397, \tTest Accuracy: 89.08 %\n",
      " \n",
      "Train Epoch: 5 [0/1867(0%)]\tTrain Loss: 0.557008\n",
      "Train Epoch: 5 [400/1867(21%)]\tTrain Loss: 0.052750\n",
      "Train Epoch: 5 [800/1867(43%)]\tTrain Loss: 0.792122\n",
      "Train Epoch: 5 [1200/1867(64%)]\tTrain Loss: 1.089398\n",
      "Train Epoch: 5 [1600/1867(86%)]\tTrain Loss: 0.347252\n",
      "\n",
      "EPOCH: 5], \tTest Loss: 0.2649, \tTest Accuracy: 81.30 %\n",
      " \n",
      "Train Epoch: 6 [0/1867(0%)]\tTrain Loss: 0.750341\n",
      "Train Epoch: 6 [400/1867(21%)]\tTrain Loss: 0.062869\n",
      "Train Epoch: 6 [800/1867(43%)]\tTrain Loss: 0.346267\n",
      "Train Epoch: 6 [1200/1867(64%)]\tTrain Loss: 0.870544\n",
      "Train Epoch: 6 [1600/1867(86%)]\tTrain Loss: 0.722647\n",
      "\n",
      "EPOCH: 6], \tTest Loss: 0.1213, \tTest Accuracy: 88.45 %\n",
      " \n",
      "Train Epoch: 7 [0/1867(0%)]\tTrain Loss: 0.169345\n",
      "Train Epoch: 7 [400/1867(21%)]\tTrain Loss: 0.526141\n",
      "Train Epoch: 7 [800/1867(43%)]\tTrain Loss: 0.069436\n",
      "Train Epoch: 7 [1200/1867(64%)]\tTrain Loss: 1.303687\n",
      "Train Epoch: 7 [1600/1867(86%)]\tTrain Loss: 0.032746\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 7], \tTest Loss: 0.1171, \tTest Accuracy: 93.70 %\n",
      " \n",
      "Train Epoch: 8 [0/1867(0%)]\tTrain Loss: 1.277873\n",
      "Train Epoch: 8 [400/1867(21%)]\tTrain Loss: 0.014275\n",
      "Train Epoch: 8 [800/1867(43%)]\tTrain Loss: 0.604660\n",
      "Train Epoch: 8 [1200/1867(64%)]\tTrain Loss: 0.456522\n",
      "Train Epoch: 8 [1600/1867(86%)]\tTrain Loss: 0.500972\n",
      "Best Model!\n",
      "\n",
      "EPOCH: 8], \tTest Loss: 0.0832, \tTest Accuracy: 96.01 %\n",
      " \n",
      "Train Epoch: 9 [0/1867(0%)]\tTrain Loss: 0.041796\n",
      "Train Epoch: 9 [400/1867(21%)]\tTrain Loss: 0.038437\n",
      "Train Epoch: 9 [800/1867(43%)]\tTrain Loss: 0.818589\n",
      "Train Epoch: 9 [1200/1867(64%)]\tTrain Loss: 0.683444\n",
      "Train Epoch: 9 [1600/1867(86%)]\tTrain Loss: 0.051108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 9], \tTest Loss: 0.0623, \tTest Accuracy: 95.59 %\n",
      " \n",
      "Train Epoch: 10 [0/1867(0%)]\tTrain Loss: 0.921399\n",
      "Train Epoch: 10 [400/1867(21%)]\tTrain Loss: 0.833272\n",
      "Train Epoch: 10 [800/1867(43%)]\tTrain Loss: 1.021673\n",
      "Train Epoch: 10 [1200/1867(64%)]\tTrain Loss: 0.047411\n",
      "Train Epoch: 10 [1600/1867(86%)]\tTrain Loss: 1.256786\n",
      "\n",
      "EPOCH: 10], \tTest Loss: 0.0679, \tTest Accuracy: 96.01 %\n",
      " \n",
      "------------------    Best Model at Epoch 8 Saved    ------------------\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = './saved_model'\n",
    "if not os.path.isdir(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "    \n",
    "for dataset in trainset_txt.keys():\n",
    "    print(\"------------------    For \", dataset, \" dataset    ------------------\")\n",
    "    \n",
    "    model = copy.deepcopy(init_model)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    if OPTIM == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    elif OPTIM == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_ep = 0\n",
    "    \n",
    "    for Epoch in range(1, EPOCHS + 1):\n",
    "        train(model, train_loader[dataset], optimizer, log_interval = 200)\n",
    "        test_loss, test_accuracy = evaluate(model, test_loader[dataset])\n",
    "        if test_accuracy > best_acc:\n",
    "            best_acc = test_accuracy\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_ep = Epoch\n",
    "            print(\"Best Model!\")\n",
    "        print(\"\\nEPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy), '\\r')\n",
    "\n",
    "    torch.save(best_model.state_dict(), SAVE_PATH+\"/{}_BS{}_{}_LR{}_EP{}_DS-{}.pt\".format(MODEL, BATCH_SIZE, OPTIM, str(LEARNING_RATE).split('.')[1], EPOCHS, dataset))\n",
    "    print(\"------------------    Best Model at Epoch {} Saved    ------------------\".format(best_ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799c3de",
   "metadata": {},
   "source": [
    "# 훈련된 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bc9d8f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1 - loss: 0.11164460807654991, acc: 94.84978540772532\n",
      "fold2 - loss: 0.09926515798558146, acc: 93.73650107991361\n",
      "fold3 - loss: 0.08881148990202678, acc: 94.83870967741936\n",
      "fold4 - loss: 0.0991357247684243, acc: 93.446088794926\n",
      "fold5 - loss: 0.08323272871166887, acc: 96.00840336134453\n",
      "average accuracy:  94.57589766426577\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "for dataset in trainset_txt.keys():\n",
    "    model_path = SAVE_PATH+\"/{}_BS{}_{}_LR{}_EP{}_DS-{}.pt\".format(MODEL, BATCH_SIZE, OPTIM, str(LEARNING_RATE).split('.')[1], EPOCHS, dataset)\n",
    "    \n",
    "    if MODEL == 'AlexNet':\n",
    "        trained_model = models.alexnet(pretrained=False)\n",
    "        trained_model._modules['classifier']._modules['6'] = nn.Linear(4096, 2, bias=True)\n",
    "    elif MODEL == 'ResNet18':\n",
    "        trained_model = models.resnet18(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'ResNet34':\n",
    "        trained_model = models.resnet34(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'ResNet50':\n",
    "        trained_model = models.resnet50(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'ResNet101':\n",
    "        trained_model = models.resnet101(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'RexNet': # BATCH_SIZE 1은 에러남\n",
    "        trained_model = rexnetv1.ReXNetV1(width_mult=1.0).cuda()\n",
    "        \n",
    "    trained_model = trained_model.cuda()\n",
    "    trained_model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    test_loss, test_accuracy = evaluate(trained_model, test_loader[dataset])\n",
    "    total_loss += test_accuracy\n",
    "    print('{} - loss: {}, acc: {}'.format(dataset, test_loss, test_accuracy))\n",
    "    \n",
    "total_loss /= len(trainset_txt)\n",
    "print(\"average accuracy: \", total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
