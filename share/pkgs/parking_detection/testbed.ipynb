{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b5767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Module Import '''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, copy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "import rexnetv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871d0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, img_path, txt_path, transforms = None):\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.img_list = [os.path.join(img_path, i.split()[0]) for i in lines]\n",
    "            self.label_list = [i.split()[1] for i in lines]\n",
    "            self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            img_path = self.img_list[index]\n",
    "            img = Image.open(img_path)\n",
    "            img = self.transforms(img)\n",
    "            label = self.label_list[index]\n",
    "        except:\n",
    "            return None\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "''' 불러온 특정 모델에 대해 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train() # 모델을 학습 상태로 지정\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        label = list(map(int, label))\n",
    "        label = torch.Tensor(label)\n",
    "        image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        optimizer.zero_grad() # 기존 할당되어 있던 gradient 값 초기화\n",
    "        output = model(image) # Forward propagation\n",
    "        loss = criterion(output, label.long()) # loss 계산\n",
    "        loss.backward() # Backpropagation을 통해 계산된 gradient 값을 각 파라미터에 할당\n",
    "        optimizer.step() # 파라미터 업데이트\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                  Epoch, batch_idx * len(image),\n",
    "                  len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                  loss.item()))\n",
    "\n",
    "''' 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval() # 모델을 평가 상태로 지정\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # 평가하는 단계에서 gradient를 통해 파라미터 값이 업데이트되는 현상을 방지\n",
    "        for image, label in test_loader:\n",
    "            label = list(map(int, label))\n",
    "            label = torch.Tensor(label)\n",
    "            image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            output = model(image) # Forward propagation\n",
    "            test_loss += criterion(output, label.long()).item() # loss 누적\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item() \n",
    "            \n",
    "    test_loss /= len(test_loader.dataset) # 평균 loss 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset) # 정확도 계산\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d6d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.11.0+cu113  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "''' 딥러닝 모델을 설계할 때 활요하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85259721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter 설정\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIM = 'SGD' # Adam\n",
    "MODEL = 'AlexNet' # AlexNet ResNet101 ResNet50 ResNet34 ResNet18 RexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f8a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 이미지 데이터 불러오기(Train set, Test set)'''\n",
    "# preprocessing 정의\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "img_path = '/root/share/datasets/Bluecom'\n",
    "trainset_txt = {'fold1': './splits/Custom_Paper/fold2345_all.txt',\n",
    "                'fold2': './splits/Custom_Paper/fold1345_all.txt',\n",
    "                'fold3': './splits/Custom_Paper/fold1245_all.txt',\n",
    "                'fold4': './splits/Custom_Paper/fold1235_all.txt',\n",
    "                'fold5': './splits/Custom_Paper/fold1234_all.txt'\n",
    "            }\n",
    "testset_txt = {'fold1': './splits/Custom_Paper/fold1_all.txt',\n",
    "            'fold2': './splits/Custom_Paper/fold2_all.txt',\n",
    "            'fold3': './splits/Custom_Paper/fold3_all.txt',\n",
    "            'fold4': './splits/Custom_Paper/fold4_all.txt',\n",
    "            'fold5': './splits/Custom_Paper/fold5_all.txt',\n",
    "            }\n",
    "\n",
    "train_loader = {}\n",
    "test_loader = {}\n",
    "\n",
    "if MODEL == 'RexNet':\n",
    "    drop_last = True\n",
    "else:\n",
    "    drop_last = False\n",
    "\n",
    "for i in range(len(trainset_txt)):\n",
    "    train_dataset = Data(img_path, trainset_txt['fold'+str(i+1)], data_transforms['train'])\n",
    "    test_dataset = Data(img_path, testset_txt['fold'+str(i+1)], data_transforms['val'])\n",
    "    train_loader['fold'+str(i+1)] = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=drop_last)\n",
    "    test_loader['fold'+str(i+1)] = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320a77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([1, 3, 224, 224]) type: torch.FloatTensor\n",
      "y_train: 1 type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (1) '''\n",
    "for (X_train, y_train) in train_loader['fold1']:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', len(y_train), 'type:', type(y_train))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee0681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' 5. 데이터 확인하기 (2) '''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(BATCH_SIZE * pltsize, pltsize))\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    plt.subplot(1, BATCH_SIZE, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
    "    plt.title('Class: ' + str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922c4332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "if MODEL == 'AlexNet':\n",
    "    model = models.alexnet(pretrained=False)\n",
    "    model._modules['classifier']._modules['6'] = nn.Linear(4096, 2, bias=True)\n",
    "elif MODEL == 'ResNet18':\n",
    "    model = models.resnet18(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'ResNet34':\n",
    "    model = models.resnet34(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'ResNet50':\n",
    "    model = models.resnet50(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'ResNet101':\n",
    "    model = models.resnet101(num_classes=2, pretrained=False)\n",
    "elif MODEL == 'RexNet': # BATCH_SIZE 1은 에러남\n",
    "    model = rexnetv1.ReXNetV1(width_mult=1.0).cuda()\n",
    "    print(model(torch.randn(BATCH_SIZE, 3, 224, 224).cuda())) \n",
    "\n",
    "init_model = copy.deepcopy(model)\n",
    "print(init_model)\n",
    "\n",
    "#for children in model.classifier.children():\n",
    "#    if isinstance(children, nn.Linear):\n",
    "#        if children.out_features == 1000:\n",
    "#            print(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06b78dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------    For  fold1  dataset    ------------------\n",
      "\n",
      "\n",
      "------------------    For  fold2  dataset    ------------------\n",
      "\n",
      "\n",
      "------------------    For  fold3  dataset    ------------------\n",
      "\n",
      "\n",
      "------------------    For  fold4  dataset    ------------------\n",
      "\n",
      "\n",
      "------------------    For  fold5  dataset    ------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' 모델 훈련'''\n",
    "SAVE_PATH = './saved_model'\n",
    "LOG_PATH = './logs'\n",
    "if not os.path.isdir(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "if not os.path.isdir(LOG_PATH):\n",
    "    os.makedirs(LOG_PATH)\n",
    "\n",
    "for dataset in trainset_txt.keys():\n",
    "    print(\"\\n------------------    For \", dataset, \" dataset    ------------------\\n\")\n",
    "\n",
    "    # 기존에 훈련된 모델이 있는지 확인\n",
    "    BEST_MODEL_PATH = SAVE_PATH+\"/{}_BS{}_{}_LR{}_EP{}_DS-{}.pt\".format(MODEL, BATCH_SIZE, OPTIM, str(LEARNING_RATE).split('.')[1], EPOCHS, dataset)\n",
    "    if os.path.exists(BEST_MODEL_PATH):\n",
    "        continue\n",
    "\n",
    "    model = copy.deepcopy(init_model)\n",
    "    model = model.cuda()\n",
    "\n",
    "    if OPTIM == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    elif OPTIM == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_log = open(LOG_PATH+\"/train_log_{}_BS{}_{}_LR{}_EP{}_DS-{}.txt\".format(MODEL, BATCH_SIZE, OPTIM, str(LEARNING_RATE).split('.')[1], EPOCHS, dataset), 'w')\n",
    "\n",
    "    best_acc = 0\n",
    "    best_ep = 0\n",
    "\n",
    "    for Epoch in range(1, EPOCHS + 1):\n",
    "        train(model, train_loader[dataset], optimizer, log_interval = 200)\n",
    "        test_loss, test_accuracy = evaluate(model, test_loader[dataset])\n",
    "        if test_accuracy > best_acc:\n",
    "            best_acc = test_accuracy\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_ep = Epoch\n",
    "            msg = \"Best Model!\\n\"\n",
    "            print(msg)\n",
    "            train_log.writelines(msg)\n",
    "        msg = \"\\nEPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy)\n",
    "        print(msg)\n",
    "        train_log.writelines(msg)\n",
    "\n",
    "    torch.save(best_model.state_dict(), BEST_MODEL_PATH)\n",
    "    msg = \"\\n------------------    Best Model at Epoch {} Saved    ------------------\\n\".format(best_ep)\n",
    "    print(msg)\n",
    "    train_log.writelines(msg)\n",
    "\n",
    "    train_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9d8f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*--------------------- Test Result ---------------------*\n",
      "\n",
      "fold1 - loss: 0.1524992298941298, acc: 96.78111587982832\n",
      "\n",
      "fold2 - loss: 0.11382482364478698, acc: 97.19222462203024\n",
      "\n",
      "fold3 - loss: 0.08616235242097432, acc: 98.06451612903226\n",
      "\n",
      "fold4 - loss: 0.06367176929724273, acc: 98.30866807610994\n",
      "\n",
      "fold5 - loss: 0.06943563478255071, acc: 97.47899159663865\n",
      "\n",
      "average accuracy: 97.56510326072788\n"
     ]
    }
   ],
   "source": [
    "''' 훈련된 모델 확인하기 '''\n",
    "test_log = open(LOG_PATH+\"/test_log_{}_BS{}_{}_LR{}_EP{}.txt\".format(MODEL, BATCH_SIZE, OPTIM, str(LEARNING_RATE).split('.')[1], EPOCHS), 'w')\n",
    "test_log.writelines(\"Dataset List\\n\")\n",
    "for dataset in trainset_txt.keys():\n",
    "    test_log.writelines(\"- {} train: {}, test: {} \\n\".format(dataset, trainset_txt[dataset], testset_txt[dataset]))\n",
    "\n",
    "msg = \"\\n*--------------------- Test Result ---------------------*\\n\"\n",
    "print(msg)\n",
    "test_log.writelines(msg)\n",
    "\n",
    "total_loss = 0\n",
    "for dataset in trainset_txt.keys():\n",
    "    model_path = SAVE_PATH+\"/{}_BS{}_{}_LR{}_EP{}_DS-{}.pt\".format(MODEL, BATCH_SIZE, OPTIM, str(LEARNING_RATE).split('.')[1], EPOCHS, dataset)\n",
    "\n",
    "    if MODEL == 'AlexNet':\n",
    "        trained_model = models.alexnet(pretrained=False)\n",
    "        trained_model._modules['classifier']._modules['6'] = nn.Linear(4096, 2, bias=True)\n",
    "    elif MODEL == 'ResNet18':\n",
    "        trained_model = models.resnet18(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'ResNet34':\n",
    "        trained_model = models.resnet34(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'ResNet50':\n",
    "        trained_model = models.resnet50(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'ResNet101':\n",
    "        trained_model = models.resnet101(num_classes=2, pretrained=False)\n",
    "    elif MODEL == 'RexNet': # BATCH_SIZE 1은 에러남\n",
    "        trained_model = rexnetv1.ReXNetV1(width_mult=1.0).cuda()\n",
    "\n",
    "    trained_model = trained_model.cuda()\n",
    "    trained_model.load_state_dict(torch.load(model_path))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    test_loss, test_accuracy = evaluate(trained_model, test_loader[dataset])\n",
    "    total_loss += test_accuracy\n",
    "    msg = '{} - loss: {}, acc: {}\\n'.format(dataset, test_loss, test_accuracy)\n",
    "    print(msg)\n",
    "    test_log.writelines(msg)\n",
    "\n",
    "total_loss /= len(trainset_txt)\n",
    "msg = \"average accuracy: {}\".format(total_loss)\n",
    "print(msg)\n",
    "test_log.writelines(msg)\n",
    "\n",
    "test_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e8ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
