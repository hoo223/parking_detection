{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b5767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. Module Import '''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, copy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import rexnetv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871d0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.11.0+cu113  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "''' 2. 딥러닝 모델을 설계할 때 활요하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85259721",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIM = 'SGD' # Adam\n",
    "MODEL = 'AlexNet' # ResNet34 ResNet18 RexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9f8a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3. 이미지 데이터 불러오기(Train set, Test set 분리하기)'''\n",
    "# preprocessing 정의\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, img_path, txt_path, transforms = None):\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.img_list = [os.path.join(img_path, i.split()[0]) for i in lines]\n",
    "            self.label_list = [i.split()[1] for i in lines]\n",
    "            self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            img_path = self.img_list[index]\n",
    "            img = Image.open(img_path)\n",
    "            img = self.transforms(img)\n",
    "            label = self.label_list[index]\n",
    "        except:\n",
    "            return None\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "img_path = '/root/share/datasets/ICNGC_data'\n",
    "trainset_txt = {'fold1': './splits/Custom_Paper/fold2345_all.txt',\n",
    "                'fold2': './splits/Custom_Paper/fold1345_all.txt',\n",
    "                'fold3': './splits/Custom_Paper/fold1245_all.txt',\n",
    "                'fold4': './splits/Custom_Paper/fold1235_all.txt',\n",
    "                'fold5': './splits/Custom_Paper/fold1234_all.txt'\n",
    "               }\n",
    "testset_txt = {'fold1': './splits/Custom_Paper/fold1_all.txt',\n",
    "               'fold2': './splits/Custom_Paper/fold2_all.txt',\n",
    "               'fold3': './splits/Custom_Paper/fold3_all.txt',\n",
    "               'fold4': './splits/Custom_Paper/fold4_all.txt',\n",
    "               'fold5': './splits/Custom_Paper/fold5_all.txt',\n",
    "              }\n",
    "\n",
    "train_loader = {}\n",
    "test_loader = {}\n",
    "\n",
    "for i in range(len(trainset_txt)):\n",
    "    train_dataset = Data(img_path, trainset_txt['fold'+str(i+1)], data_transforms['train'])\n",
    "    test_dataset = Data(img_path, testset_txt['fold'+str(i+1)], data_transforms['val'])\n",
    "    train_loader['fold'+str(i+1)] = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    test_loader['fold'+str(i+1)] = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "320a77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([1, 3, 224, 224]) type: torch.FloatTensor\n",
      "y_train: 1 type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (1) '''\n",
    "for (X_train, y_train) in train_loader['fold1']:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', len(y_train), 'type:', type(y_train))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ee0681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' 5. 데이터 확인하기 (2) '''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(BATCH_SIZE * pltsize, pltsize))\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    plt.subplot(1, BATCH_SIZE, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
    "    plt.title('Class: ' + str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc11d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 6. 불러온 특정 모델에 대해 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train() # 모델을 학습 상태로 지정\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        label = list(map(int, label))\n",
    "        label = torch.Tensor(label)\n",
    "        image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        optimizer.zero_grad() # 기존 할당되어 있던 gradient 값 초기화\n",
    "        output = model(image) # Forward propagation\n",
    "        loss = criterion(output, label.long()) # loss 계산\n",
    "        loss.backward() # Backpropagation을 통해 계산된 gradient 값을 각 파라미터에 할당\n",
    "        optimizer.step() # 파라미터 업데이트\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                  Epoch, batch_idx * len(image),\n",
    "                  len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                  loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c1f5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 7. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval() # 모델을 평가 상태로 지정\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # 평가하는 단계에서 gradient를 통해 파라미터 값이 업데이트되는 현상을 방지\n",
    "        for image, label in test_loader:\n",
    "            label = list(map(int, label))\n",
    "            label = torch.Tensor(label)\n",
    "            image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            output = model(image) # Forward propagation\n",
    "            test_loss += criterion(output, label.long()).item() # loss 누적\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item() \n",
    "            \n",
    "    test_loss /= len(test_loader.dataset) # 평균 loss 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset) # 정확도 계산\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "922c4332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "if MODEL == 'AlexNet':\n",
    "    model = models.alexnet(pretrained=False)\n",
    "    model._modules['classifier']._modules['6'] = nn.Linear(4096, 2, bias=True)\n",
    "elif MODEL == 'ResNet18':\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "elif MODEL == 'ResNet34':\n",
    "    model = models.resnet34(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "elif MODEL == 'RexNet':\n",
    "    model = rexnetv1.ReXNetV1(input_ch=3, classes=2).cuda()\n",
    "    \n",
    "init_model = copy.deepcopy(model)\n",
    "print(init_model)\n",
    "\n",
    "#for children in model.classifier.children():\n",
    "#    if isinstance(children, nn.Linear):\n",
    "#        if children.out_features == 1000:\n",
    "#            print(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d06b78dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------    For  fold1  dataset    ------------------\n",
      "Train Epoch: 1 [0/1877(0%)]\tTrain Loss: 0.689633\n",
      "Train Epoch: 1 [200/1877(11%)]\tTrain Loss: 0.611640\n",
      "Train Epoch: 1 [400/1877(21%)]\tTrain Loss: 0.874768\n",
      "Train Epoch: 1 [600/1877(32%)]\tTrain Loss: 0.834699\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m best_ep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader[dataset])\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_accuracy \u001b[38;5;241m>\u001b[39m best_acc:\n",
      "Cell \u001b[0;32mIn [22], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[1;32m      5\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, label))\n\u001b[1;32m      6\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(label)\n\u001b[0;32m----> 7\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 기존 정의한 장비에 할당\u001b[39;00m\n\u001b[1;32m      8\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;66;03m# 기존 정의한 장비에 할당\u001b[39;00m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# 기존 할당되어 있던 gradient 값 초기화\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SAVE_PATH = './saved_model'\n",
    "if not os.path.isdir(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "    \n",
    "for dataset in trainset_txt.keys():\n",
    "    print(\"------------------    For \", dataset, \" dataset    ------------------\")\n",
    "    \n",
    "    model = copy.deepcopy(init_model)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    if OPTIM == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    elif OPTIM == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_ep = 0\n",
    "    \n",
    "    for Epoch in range(1, EPOCHS + 1):\n",
    "        train(model, train_loader[dataset], optimizer, log_interval = 200)\n",
    "        test_loss, test_accuracy = evaluate(model, test_loader[dataset])\n",
    "        if test_accuracy > best_acc:\n",
    "            best_acc = test_accuracy\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_ep = Epoch+1\n",
    "            print(\"Best Model!\")\n",
    "        print(\"\\nEPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy), '\\r')\n",
    "\n",
    "    torch.save(best_model.state_dict(), SAVE_PATH+\"/{}_BS{}_{}_LR{}_EP{}_DS-{}.pt\".format(MODEL, BATCH_SIZE, OPTIM, str(LEARNING_RATE).split('.')[1], EPOCHS, dataset))\n",
    "    print(\"------------------    Best Model at Epoch {} Saved    ------------------\".format(best_ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799c3de",
   "metadata": {},
   "source": [
    "# 훈련된 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ea7f5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = SAVE_PATH+\"/{}_BS{}_{}_LR{}_EP{}.pt\".format(MODEL, BATCH_SIZE, OPTIM, LEARNING_RATE, EPOCHS)\n",
    "trained_model = models.alexnet(pretrained=False)\n",
    "trained_model._modules['classifier']._modules['6'] = nn.Linear(4096, 2, bias=True)\n",
    "trained_model = trained_model.cuda()\n",
    "print(model)\n",
    "trained_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9d8f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06306391112237013 99.15966386554622\n"
     ]
    }
   ],
   "source": [
    "for dataset in trainset_txt.keys():\n",
    "    test_loss, test_accuracy = evaluate(trained_model, test_loader[dataset])\n",
    "    print('{} - loss: {}, acc: {}'.format(dataset, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
