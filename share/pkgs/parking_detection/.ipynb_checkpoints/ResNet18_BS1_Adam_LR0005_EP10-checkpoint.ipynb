{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b5767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. Module Import '''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871d0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.11.0+cu113  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "''' 2. 딥러닝 모델을 설계할 때 활요하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85259721",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIM = 'Adam'\n",
    "MODEL = 'ResNet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f8a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3. 이미지 데이터 불러오기(Train set, Test set 분리하기)'''\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "# preprocessing 정의\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, img_path, txt_path, transforms = None):\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.img_list = [os.path.join(img_path, i.split()[0]) for i in lines]\n",
    "            self.label_list = [i.split()[1] for i in lines]\n",
    "            self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            img_path = self.img_list[index]\n",
    "            img = Image.open(img_path)\n",
    "            img = self.transforms(img)\n",
    "            label = self.label_list[index]\n",
    "        except:\n",
    "            return None\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "img_path = '/root/share/datasets/ICNGC_data'\n",
    "trainset_txt = './splits/Custom_Paper/fold1234_all.txt'\n",
    "testset_txt = './splits/Custom_Paper/fold5_all.txt'\n",
    "train_dataset = Data(img_path, trainset_txt, data_transforms['train'])\n",
    "test_dataset = Data(img_path, testset_txt, data_transforms['val'])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "320a77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([1, 3, 224, 224]) type: torch.FloatTensor\n",
      "y_train: 1 type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "''' 4. 데이터 확인하기 (1) '''\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', len(y_train), 'type:', type(y_train))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee0681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' 5. 데이터 확인하기 (2) '''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(BATCH_SIZE * pltsize, pltsize))\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    plt.subplot(1, BATCH_SIZE, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
    "    plt.title('Class: ' + str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc11d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 6. 불러온 특정 모델에 대해 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train() # 모델을 학습 상태로 지정\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        label = list(map(int, label))\n",
    "        label = torch.Tensor(label)\n",
    "        image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "        optimizer.zero_grad() # 기존 할당되어 있던 gradient 값 초기화\n",
    "        output = model(image) # Forward propagation\n",
    "        loss = criterion(output, label.long()) # loss 계산\n",
    "        loss.backward() # Backpropagation을 통해 계산된 gradient 값을 각 파라미터에 할당\n",
    "        optimizer.step() # 파라미터 업데이트\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                  Epoch, batch_idx * len(image),\n",
    "                  len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                  loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1f5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 7. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval() # 모델을 평가 상태로 지정\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # 평가하는 단계에서 gradient를 통해 파라미터 값이 업데이트되는 현상을 방지\n",
    "        for image, label in test_loader:\n",
    "            label = list(map(int, label))\n",
    "            label = torch.Tensor(label)\n",
    "            image = image.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            label = label.to(DEVICE) # 기존 정의한 장비에 할당\n",
    "            output = model(image) # Forward propagation\n",
    "            test_loss += criterion(output, label.long()).item() # loss 누적\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item() \n",
    "            \n",
    "    test_loss /= len(test_loader.dataset) # 평균 loss 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset) # 정확도 계산\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922c4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d06b78dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1867(0%)]\tTrain Loss: 1.101482\n",
      "Train Epoch: 1 [200/1867(11%)]\tTrain Loss: 0.452302\n",
      "Train Epoch: 1 [400/1867(21%)]\tTrain Loss: 0.030618\n",
      "Train Epoch: 1 [600/1867(32%)]\tTrain Loss: 0.394622\n",
      "Train Epoch: 1 [800/1867(43%)]\tTrain Loss: 0.219053\n",
      "Train Epoch: 1 [1000/1867(54%)]\tTrain Loss: 0.031802\n",
      "Train Epoch: 1 [1200/1867(64%)]\tTrain Loss: 0.040401\n",
      "Train Epoch: 1 [1400/1867(75%)]\tTrain Loss: 0.076954\n",
      "Train Epoch: 1 [1600/1867(86%)]\tTrain Loss: 0.076581\n",
      "Train Epoch: 1 [1800/1867(96%)]\tTrain Loss: 0.150091\n",
      "\n",
      "EPOCH: 1], \tTest Loss: 1.8710, \tTest Accuracy: 64.50 %\n",
      "\n",
      "Train Epoch: 2 [0/1867(0%)]\tTrain Loss: 2.048438\n",
      "Train Epoch: 2 [200/1867(11%)]\tTrain Loss: 0.142092\n",
      "Train Epoch: 2 [400/1867(21%)]\tTrain Loss: 0.096471\n",
      "Train Epoch: 2 [600/1867(32%)]\tTrain Loss: 0.041837\n",
      "Train Epoch: 2 [800/1867(43%)]\tTrain Loss: 0.006622\n",
      "Train Epoch: 2 [1000/1867(54%)]\tTrain Loss: 0.047279\n",
      "Train Epoch: 2 [1200/1867(64%)]\tTrain Loss: 2.053357\n",
      "Train Epoch: 2 [1400/1867(75%)]\tTrain Loss: 0.373196\n",
      "Train Epoch: 2 [1600/1867(86%)]\tTrain Loss: 0.018159\n",
      "Train Epoch: 2 [1800/1867(96%)]\tTrain Loss: 0.018841\n",
      "\n",
      "EPOCH: 2], \tTest Loss: 1.5072, \tTest Accuracy: 68.70 %\n",
      "\n",
      "Train Epoch: 3 [0/1867(0%)]\tTrain Loss: 0.016157\n",
      "Train Epoch: 3 [200/1867(11%)]\tTrain Loss: 0.035871\n",
      "Train Epoch: 3 [400/1867(21%)]\tTrain Loss: 0.314188\n",
      "Train Epoch: 3 [600/1867(32%)]\tTrain Loss: 0.007184\n",
      "Train Epoch: 3 [800/1867(43%)]\tTrain Loss: 0.014560\n",
      "Train Epoch: 3 [1000/1867(54%)]\tTrain Loss: 0.026678\n",
      "Train Epoch: 3 [1200/1867(64%)]\tTrain Loss: 0.000694\n",
      "Train Epoch: 3 [1400/1867(75%)]\tTrain Loss: 0.021483\n",
      "Train Epoch: 3 [1600/1867(86%)]\tTrain Loss: 0.049771\n",
      "Train Epoch: 3 [1800/1867(96%)]\tTrain Loss: 0.061888\n",
      "\n",
      "EPOCH: 3], \tTest Loss: 0.7272, \tTest Accuracy: 76.89 %\n",
      "\n",
      "Train Epoch: 4 [0/1867(0%)]\tTrain Loss: 0.324959\n",
      "Train Epoch: 4 [200/1867(11%)]\tTrain Loss: 0.002875\n",
      "Train Epoch: 4 [400/1867(21%)]\tTrain Loss: 0.106348\n",
      "Train Epoch: 4 [600/1867(32%)]\tTrain Loss: 0.101407\n",
      "Train Epoch: 4 [800/1867(43%)]\tTrain Loss: 0.014490\n",
      "Train Epoch: 4 [1000/1867(54%)]\tTrain Loss: 0.010153\n",
      "Train Epoch: 4 [1200/1867(64%)]\tTrain Loss: 0.003545\n",
      "Train Epoch: 4 [1400/1867(75%)]\tTrain Loss: 0.004631\n",
      "Train Epoch: 4 [1600/1867(86%)]\tTrain Loss: 0.942779\n",
      "Train Epoch: 4 [1800/1867(96%)]\tTrain Loss: 0.016514\n",
      "\n",
      "EPOCH: 4], \tTest Loss: 0.6151, \tTest Accuracy: 78.36 %\n",
      "\n",
      "Train Epoch: 5 [0/1867(0%)]\tTrain Loss: 0.001816\n",
      "Train Epoch: 5 [200/1867(11%)]\tTrain Loss: 0.007652\n",
      "Train Epoch: 5 [400/1867(21%)]\tTrain Loss: 0.007390\n",
      "Train Epoch: 5 [600/1867(32%)]\tTrain Loss: 0.021577\n",
      "Train Epoch: 5 [800/1867(43%)]\tTrain Loss: 0.011392\n",
      "Train Epoch: 5 [1000/1867(54%)]\tTrain Loss: 0.358408\n",
      "Train Epoch: 5 [1200/1867(64%)]\tTrain Loss: 0.004156\n",
      "Train Epoch: 5 [1400/1867(75%)]\tTrain Loss: 0.012231\n",
      "Train Epoch: 5 [1600/1867(86%)]\tTrain Loss: 0.001990\n",
      "Train Epoch: 5 [1800/1867(96%)]\tTrain Loss: 0.006169\n",
      "\n",
      "EPOCH: 5], \tTest Loss: 1.9428, \tTest Accuracy: 62.39 %\n",
      "\n",
      "Train Epoch: 6 [0/1867(0%)]\tTrain Loss: 0.205725\n",
      "Train Epoch: 6 [200/1867(11%)]\tTrain Loss: 0.016016\n",
      "Train Epoch: 6 [400/1867(21%)]\tTrain Loss: 0.003517\n",
      "Train Epoch: 6 [600/1867(32%)]\tTrain Loss: 0.126469\n",
      "Train Epoch: 6 [800/1867(43%)]\tTrain Loss: 0.000310\n",
      "Train Epoch: 6 [1000/1867(54%)]\tTrain Loss: 0.026253\n",
      "Train Epoch: 6 [1200/1867(64%)]\tTrain Loss: 0.000608\n",
      "Train Epoch: 6 [1400/1867(75%)]\tTrain Loss: 0.117328\n",
      "Train Epoch: 6 [1600/1867(86%)]\tTrain Loss: 0.992549\n",
      "Train Epoch: 6 [1800/1867(96%)]\tTrain Loss: 0.194221\n",
      "\n",
      "EPOCH: 6], \tTest Loss: 2.5368, \tTest Accuracy: 62.82 %\n",
      "\n",
      "Train Epoch: 7 [0/1867(0%)]\tTrain Loss: 0.013855\n",
      "Train Epoch: 7 [200/1867(11%)]\tTrain Loss: 0.016214\n",
      "Train Epoch: 7 [400/1867(21%)]\tTrain Loss: 0.001749\n",
      "Train Epoch: 7 [600/1867(32%)]\tTrain Loss: 0.002553\n",
      "Train Epoch: 7 [800/1867(43%)]\tTrain Loss: 0.003992\n",
      "Train Epoch: 7 [1000/1867(54%)]\tTrain Loss: 0.010545\n",
      "Train Epoch: 7 [1200/1867(64%)]\tTrain Loss: 0.002593\n",
      "Train Epoch: 7 [1400/1867(75%)]\tTrain Loss: 0.129867\n",
      "Train Epoch: 7 [1600/1867(86%)]\tTrain Loss: 0.137816\n",
      "Train Epoch: 7 [1800/1867(96%)]\tTrain Loss: 0.017759\n",
      "\n",
      "EPOCH: 7], \tTest Loss: 2.4671, \tTest Accuracy: 62.61 %\n",
      "\n",
      "Train Epoch: 8 [0/1867(0%)]\tTrain Loss: 0.037041\n",
      "Train Epoch: 8 [200/1867(11%)]\tTrain Loss: 0.016868\n",
      "Train Epoch: 8 [400/1867(21%)]\tTrain Loss: 0.008281\n",
      "Train Epoch: 8 [600/1867(32%)]\tTrain Loss: 0.000549\n",
      "Train Epoch: 8 [800/1867(43%)]\tTrain Loss: 0.000591\n",
      "Train Epoch: 8 [1000/1867(54%)]\tTrain Loss: 0.002644\n",
      "Train Epoch: 8 [1200/1867(64%)]\tTrain Loss: 0.021744\n",
      "Train Epoch: 8 [1400/1867(75%)]\tTrain Loss: 0.000396\n",
      "Train Epoch: 8 [1600/1867(86%)]\tTrain Loss: 0.027169\n",
      "Train Epoch: 8 [1800/1867(96%)]\tTrain Loss: 0.066313\n",
      "\n",
      "EPOCH: 8], \tTest Loss: 1.9161, \tTest Accuracy: 68.91 %\n",
      "\n",
      "Train Epoch: 9 [0/1867(0%)]\tTrain Loss: 0.030954\n",
      "Train Epoch: 9 [200/1867(11%)]\tTrain Loss: 1.061385\n",
      "Train Epoch: 9 [400/1867(21%)]\tTrain Loss: 0.002415\n",
      "Train Epoch: 9 [600/1867(32%)]\tTrain Loss: 0.000413\n",
      "Train Epoch: 9 [800/1867(43%)]\tTrain Loss: 0.020641\n",
      "Train Epoch: 9 [1000/1867(54%)]\tTrain Loss: 0.010438\n",
      "Train Epoch: 9 [1200/1867(64%)]\tTrain Loss: 0.002959\n",
      "Train Epoch: 9 [1400/1867(75%)]\tTrain Loss: 0.035895\n",
      "Train Epoch: 9 [1600/1867(86%)]\tTrain Loss: 0.087687\n",
      "Train Epoch: 9 [1800/1867(96%)]\tTrain Loss: 0.000241\n",
      "\n",
      "EPOCH: 9], \tTest Loss: 1.8255, \tTest Accuracy: 68.49 %\n",
      "\n",
      "Train Epoch: 10 [0/1867(0%)]\tTrain Loss: 0.016314\n",
      "Train Epoch: 10 [200/1867(11%)]\tTrain Loss: 0.045726\n",
      "Train Epoch: 10 [400/1867(21%)]\tTrain Loss: 0.050195\n",
      "Train Epoch: 10 [600/1867(32%)]\tTrain Loss: 0.011607\n",
      "Train Epoch: 10 [800/1867(43%)]\tTrain Loss: 0.029712\n",
      "Train Epoch: 10 [1000/1867(54%)]\tTrain Loss: 0.007109\n",
      "Train Epoch: 10 [1200/1867(64%)]\tTrain Loss: 0.003523\n",
      "Train Epoch: 10 [1400/1867(75%)]\tTrain Loss: 0.005861\n",
      "Train Epoch: 10 [1600/1867(86%)]\tTrain Loss: 0.269227\n",
      "Train Epoch: 10 [1800/1867(96%)]\tTrain Loss: 0.007550\n",
      "\n",
      "EPOCH: 10], \tTest Loss: 0.4738, \tTest Accuracy: 82.14 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if OPTIM == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_acc = 0\n",
    "SAVE_PATH = './saved_model/{}_BS{}_{}_LR{}_EP'.format(MODEL, BATCH_SIZE, OPTIM, LEARNING_RATE, EPOCHS)\n",
    "\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    if test_accuracy > best_acc:\n",
    "        torch.save(model.state_dict(), SAVE_PATH+\"{}.pt\".format(Epoch))\n",
    "    print(\"\\nEPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccbd47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
