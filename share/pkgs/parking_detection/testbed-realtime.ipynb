{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b5767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Module Import '''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as img\n",
    "import os, copy, shutil, cv2\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "import rexnetv1\n",
    "\n",
    "from utils.utils import Utils\n",
    "# 함수 클래스 인스턴스화\n",
    "ut = Utils()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d81b2",
   "metadata": {},
   "source": [
    "# AI 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cf59a",
   "metadata": {},
   "source": [
    "### GPU 모드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d6d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.11.0+cu113  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "''' 딥러닝 모델을 설계할 때 활요하는 장비 확인 '''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e109329",
   "metadata": {},
   "source": [
    "### Hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85259721",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "OPTIM = 'SGD' # Adam\n",
    "MODEL = 'AlexNet' # AlexNet ResNet101 ResNet50 ResNet34 ResNet18 RexNet\n",
    "NUM_CLASS = 2\n",
    "PRETRAINED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e32c05",
   "metadata": {},
   "source": [
    "### Preprocessing 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568865e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcf5ae4",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922c4332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if MODEL == 'AlexNet':\n",
    "    model = models.alexnet(pretrained=PRETRAINED)\n",
    "    model._modules['classifier']._modules['6'] = nn.Linear(4096, NUM_CLASS, bias=True)\n",
    "elif MODEL == 'ResNet18':\n",
    "    model = models.resnet18(pretrained=PRETRAINED)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASS)\n",
    "elif MODEL == 'ResNet34':\n",
    "    model = models.resnet34(pretrained=PRETRAINED)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASS)\n",
    "elif MODEL == 'ResNet50':\n",
    "    model = models.resnet50(pretrained=PRETRAINED)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASS)\n",
    "elif MODEL == 'ResNet101':\n",
    "    model = models.resnet101(pretrained=PRETRAINED)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASS)\n",
    "elif MODEL == 'RexNet': # BATCH_SIZE 1은 에러남\n",
    "    model = rexnetv1.ReXNetV1(width_mult=1.0).cuda()\n",
    "    if PRETRAINED:\n",
    "        model.load_state_dict(torch.load('./rexnetv1_1.0.pth'))\n",
    "\n",
    "init_model = copy.deepcopy(model)\n",
    "print(init_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06b78dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model exists!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best 모델 파라미터 불러오기\n",
    "BEST_MODEL_PATH = './saved_model/AlexNet_Pretrained_BS1_SGD_LR0005_EP10_TR-Custom_Paper-fold12345_all_VD-Additional-total_20221028+empty_generated_overlap_removed_valid.pt'\n",
    "\n",
    "# 모델 초기화 \n",
    "model = copy.deepcopy(init_model)\n",
    "model = model.cuda()\n",
    "\n",
    "# Optimizer 및 loss 정의\n",
    "if OPTIM == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "elif OPTIM == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 사전에 훈련된 모델이 존재하면 테스트만 진행하고 다음으로 넘어감 \n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(\"Trained model exists!\\n\")\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846b405",
   "metadata": {},
   "source": [
    "# 카메라별 라벨링 정보 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb762b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cam/60/DJI_0013_002-018.MP4_snapshot_02.00_[2022.09.05_15.10.53].jpg\n",
      "./cam/58/DJI_0013_002-018.MP4_snapshot_01.42_[2022.09.05_15.10.33].jpg\n",
      "./cam/57/DJI_0013_002-018.MP4_snapshot_00.48_[2022.09.05_15.09.30].jpg\n"
     ]
    }
   ],
   "source": [
    "path = './cam'\n",
    "annotation_file = 'annotations.xml'\n",
    "filePath = os.path.join(path, annotation_file)\n",
    "\n",
    "# annotation 파일 불러오기\n",
    "tree = ET.parse(filePath)\n",
    "root = tree.getroot()\n",
    "cams = root.findall(\"cam\")\n",
    "\n",
    "cam_list = {}\n",
    "gts = []\n",
    "\n",
    "for cam in cams:\n",
    "    cam_attrib = cam.attrib\n",
    "    cam_id = cam_attrib['id']\n",
    "    frame = cam_attrib['name']\n",
    "    image_path = os.path.join(path, cam_id, frame)\n",
    "    image_witdh = cam.attrib.get('width')\n",
    "    image_height = cam.attrib.get('height')\n",
    "    print(image_path)\n",
    "    bb_points_list = []\n",
    "    gts = [] # Ground Truth -> 실제 서비스 시에는 없는 정보\n",
    "    \n",
    "    polylines = cam.findall('polyline')\n",
    "    polygons = cam.findall('polygon')\n",
    "    \n",
    "    for polyline in polylines: # 있음\n",
    "        polyline_label, width, bb_points = ut.get_occupied_info(polyline, image_witdh, image_height)\n",
    "        bb_points_list.append(bb_points)\n",
    "        gts.append(1) # Ground Truth -> 실제 서비스 시에는 없는 정보\n",
    "        \n",
    "    for polygon in polygons:\n",
    "        label = polygon.get('label')\n",
    "        if label == '없음': # 없음\n",
    "            empty_label, width, bb_points, poly_points, empty_type = ut.get_empty_info(polygon, image_witdh, image_height)\n",
    "            bb_points_list.append(bb_points)\n",
    "            gts.append(0) # Ground Truth -> 실제 서비스 시에는 없는 정보\n",
    "    \n",
    "    cam = {'frame': image_path, 'bb_points_list': bb_points_list, 'gts': gts}\n",
    "    cam_list[cam_id] = cam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c628908",
   "metadata": {},
   "source": [
    "# 각 카메라 별로 라벨링 정보를 읽어와 입력된 frame에 대해 AI 분석 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf06b489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam 60\n",
      "\n",
      "[correct] pred: 1 gt: 1, result: True\n",
      "\n",
      "[correct] pred: 1 gt: 1, result: True\n",
      "\n",
      "[correct] pred: 1 gt: 1, result: True\n",
      "\n",
      "cam 58\n",
      "\n",
      "[correct] pred: 1 gt: 1, result: True\n",
      "\n",
      "[correct] pred: 1 gt: 1, result: True\n",
      "\n",
      "[correct] pred: 1 gt: 1, result: True\n",
      "\n",
      "cam 57\n",
      "\n",
      "[correct] pred: 0 gt: 0, result: True\n",
      "\n",
      "[correct] pred: 0 gt: 0, result: True\n",
      "\n",
      "[correct] pred: 0 gt: 0, result: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_txt = open(os.path.join(path, 'result.txt'), 'w')\n",
    "\n",
    "for cam_id in cam_list.keys():\n",
    "    msg = 'cam {}\\n'.format(cam_id)\n",
    "    print(msg)\n",
    "    result_txt.write(msg)\n",
    "    \n",
    "    cam = cam_list[cam_id]\n",
    "    src = cv2.imread(cam['frame'], cv2.IMREAD_COLOR) # 약 80ms -> 추후 서비스 시 이 부분을 실제 카메라에서 입력되는 frame으로 변경 \n",
    "    \n",
    "    for i, bb_points in enumerate(cam['bb_points_list']): # 각 주차면마다 # 한 loop당 약 0.5ms\n",
    "        gt = cam['gts'][i] # Ground Truth -> 실제 서비스 시에는 없는 정보\n",
    "        \n",
    "        # Patch 추출\n",
    "        srcPoint = np.float32([bb_points[3], bb_points[2], bb_points[1] , bb_points[0]]) # 변환 전 4개 좌표 \n",
    "        dstPoint = np.array([[0, 0], [256, 0], [256, 256], [0, 256]], dtype=np.float32) # 변환 후 4개 좌표\n",
    "        matrix = cv2.getPerspectiveTransform(srcPoint, dstPoint) # Perspective transformation 생성\n",
    "        patch_img = cv2.warpPerspective(src, matrix, (256, 256)) # 변환\n",
    "        \n",
    "        # 이미지 출력\n",
    "        #plt.imshow(patch_img)\n",
    "        #plt.show()\n",
    "        \n",
    "        # 이미지 전처리\n",
    "        img_preprocessed = data_transforms['test'](patch_img).to(DEVICE) # 약 0.3ms [3, 256, 256]\n",
    "        img_preprocessed = img_preprocessed[None, :] # [1, 3, 256, 256]\n",
    "        \n",
    "        # Inference\n",
    "        output = model(img_preprocessed) # 각 클래스 확률 값 # 약 0.8ms for 1 image\n",
    "        prediction = output.max(1, keepdim = True)[1] # 예측하는 클래스 번호\n",
    "        \n",
    "        # 결과 비교\n",
    "        result = prediction.eq(torch.Tensor([gt]).to(DEVICE).view_as(prediction))\n",
    "\n",
    "        if ~result: # 틀림\n",
    "            msg = \"[incorrect] pred: {} gt: {}, result: {}\\n\".format(prediction.cpu().numpy()[0][0], gt, result.cpu().numpy()[0][0])  \n",
    "        else: # 맞음\n",
    "            msg = \"[correct] pred: {} gt: {}, result: {}\\n\".format(prediction.cpu().numpy()[0][0], gt, result.cpu().numpy()[0][0])\n",
    "            \n",
    "        print(msg)\n",
    "        result_txt.write(msg)\n",
    "\n",
    "result_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a283f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
